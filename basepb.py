import warnings
warnings.filterwarnings("ignore")

import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from streamlit_plotly_events import plotly_events
from datetime import datetime, timedelta
import pytz
import feedparser
import urllib.parse
import html
import re
import time
import locale

# Set locale for proper number formatting
try:
    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
except:
    pass

# --------------------------
# ML libraries
# --------------------------
HAS_PROPHET = False
HAS_ARIMA = False
HAS_SKLEARN = False
HAS_TF = False

try:
    from prophet import Prophet
    HAS_PROPHET = True
except:
    Prophet = None

try:
    from statsmodels.tsa.arima.model import ARIMA
    HAS_ARIMA = True
except:
    ARIMA = None

try:
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.preprocessing import MinMaxScaler
    HAS_SKLEARN = True
except:
    RandomForestRegressor = None
    MinMaxScaler = None

try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional
    from tensorflow.keras import optimizers
    from tensorflow.keras import callbacks
    HAS_TF = True
except:
    tf = None
    keras = None
    layers = None

# --------------------------
# Translation Dictionaries
# --------------------------
translations = {
    "en": {
        "disclaimer_title": "DISCLAIMER",
        "disclaimer_text": """Point blank provides stock market data, analysis, and predictive tools for **educational and informational purposes only**.  

- Point blank does **not** provide financial, investment, trading, or legal advice.  
- All information, forecasts, and analytics generated by Point blank are **estimates only** and may be inaccurate, incomplete, or outdated.  
- Stock market investments are inherently **risky and volatile**. Past performance is not indicative of future results.  
- Users are solely responsible for any investment or trading decisions made based on Point blank's content.  
- The developers, owners, affiliates, and contributors of Point blank shall **not be held liable** for any financial losses, damages, or consequences arising directly or indirectly from its use.  

By using Point blank, you acknowledge that you understand these risks and agree to use the website at your own discretion and responsibility.  
For personalized financial guidance, please consult a licensed financial advisor.""",
        "accept_disclaimer": "I have read and accept the disclaimer",
        "title": "POINT.BLANK",
        "ticker_label": "Ticker",
        "period_label": "History period",
        "interval_label": "Interval",
        "indicators_label": "Show Indicators",
        "run_button": "Run All",
        "fetching_data": "Fetching stock data and computing indicators...",
        "no_data": "No data retrieved. Check ticker or network connection.",
        "price_chart": "Price Chart & Technical Indicators",
        "ai_forecasts": "AI Forecasts",
        "running_models": "Running forecasting models...",
        "news": "NEWS",
        "fetching_news": "Fetching latest news...",
        "no_articles": "No recent articles found.",
        "export_data": "Export Data",
        "download_csv": "Download Raw Data (CSV)",
        "download_json": "Download Historical Data (JSON)",
        "download_news": "Download News Data (CSV)",
        "recent_data": "Recent Historical Data",
        "select_ticker": "Select a ticker and press **'Run'** to fetch comprehensive stock analysis with forecasts and news!",
        "model_status": "Model Availability Status",
        "available": "Available",
        "missing": "Missing",
        "date": "Date",
        "open": "Open",
        "high": "High",
        "low": "Low",
        "close": "Close",
        "prophet": "Prophet",
        "arima": "ARIMA",
        "random_forest": "Random Forest",
        "lstm": "LSTM",
        "historical": "Historical",
        "forecast": "Forecast",
        "lower_bound": "Lower Bound",
        "upper_bound": "Upper Bound",
        "download": "Download",
        "warning": "Please accept the disclaimer to use the app.",
        "error_fetching": "Error fetching data",
        "error_computing": "Error computing indicators",
        "error_chart": "Error creating chart",
        "error_metrics": "Error displaying metrics",
        "error_forecasts": "Error displaying forecasts",
        "error_news": "Error displaying news",
        "error_export": "Error creating export section",
        "prophet_error": "Enhanced Prophet error",
        "arima_error": "ARIMA error",
        "rf_error": "RandomForest error",
        "lstm_error": "Enhanced LSTM error",
        "no_models": "No forecasting models available. Install required libraries (prophet, statsmodels, sklearn, tensorflow).",
        "lstm_warning1": "Dataset too small for LSTM. Skipping LSTM forecasting.",
        "lstm_warning2": "Not enough sequences for LSTM training. Skipping LSTM.",
        "language_select": "Select your preferred language",
        "city_select": "Select your city on the globe",
        "current_time": "Current Time"
    },
    "es": {
        "disclaimer_title": "DESCARGO DE RESPONSABILIDAD",
        "disclaimer_text": """Point blank proporciona datos del mercado de valores, análisis y herramientas predictivas únicamente con **fines educativos e informativos**.  

- Point blank **no** proporciona asesoramiento financiero, de inversión, comercial o legal.  
- Toda la información, pronósticos y análisis generados por Point blank son **solo estimaciones** and pueden ser inexactos, incompletos o obsoletos.  
- Las inversiones en el mercado de valores son inherentemente **riesgosas y volátiles**. El rendimiento pasado no es indicativo de resultados futuros.  
- Los usuarios son los únicos responsables de cualquier decisión de inversión o negociación tomada basándose en el contenido de Point blank.  
- Los desarrolladores, propietarios, afiliados y colaboradores de Point blank **no serán responsables** de ninguna pérdida financiera, daño o consecuencia que surja directa o indirectamente de su uso.  

Al utilizar Point blank, usted reconoce que comprende estos riesgos y acepta utilizar el sitio web bajo su propia discreción y responsabilidad.  
Para orientación financiera personalizada, consulte a un asesor financiero autorizado.""",
        "accept_disclaimer": "He leído y acepto el descargo de responsabilidad",
        "title": "PUNTO.BLANCO",
        "ticker_label": "Ticker",
        "period_label": "Período de historial",
        "interval_label": "Intervalo",
        "indicators_label": "Mostrar indicadores",
        "run_button": "Ejecutar todo",
        "fetching_data": "Obteniendo datos de acciones and calculando indicadores...",
        "no_data": "No se recuperaron datos. Verifique el ticker o la conexión de red.",
        "price_chart": "Gráfico de precios e indicadores técnicos",
        "ai_forecasts": "Pronósticos de IA",
        "running_models": "Ejecutando modelos de pronóstico...",
        "news": "NOTICIAS",
        "fetching_news": "Obteniendo noticias recientes...",
        "no_articles": "No se encontraron artículos recientes.",
        "export_data": "Exportar datos",
        "download_csv": "Descargar datos brutos (CSV)",
        "download_json": "Descargar datos históricos (JSON)",
        "download_news": "Descargar datos de noticias (CSV)",
        "recent_data": "Datos históricos recientes",
        "select_ticker": "¡Seleccione un ticker and presione **'Ejecutar'** para obtener un análisis completo de acciones con pronósticos and noticias!",
        "model_status": "Estado de disponibilidad del modelo",
        "available": "Disponible",
        "missing": "Falta",
        "date": "Fecha",
        "open": "Apertura",
        "high": "Máximo",
        "low": "Mínimo",
        "close": "Cierre",
        "prophet": "Profeta",
        "arima": "ARIMA",
        "random_forest": "Bosque Aleatorio",
        "lstm": "LSTM",
        "historical": "Histórico",
        "forecast": "Pronóstico",
        "lower_bound": "Límite inferior",
        "upper_bound": "Límite superior",
        "download": "Descargar",
        "warning": "Por favor, acepte el descargo de responsabilidad para usar la aplicación.",
        "error_fetching": "Error al obtener datos",
        "error_computing": "Error al calcular indicadores",
        "error_chart": "Error al crear gráfico",
        "error_metrics": "Error al mostrar métricas",
        "error_forecasts": "Error al mostrar pronósticos",
        "error_news": "Error al mostrar noticias",
        "error_export": "Error al crear sección de exportación",
        "prophet_error": "Error de Profeta mejorado",
        "arima_error": "Error de ARIMA",
        "rf_error": "Error de Bosque Aleatorio",
        "lstm_error": "Error de LSTM mejorado",
        "no_models": "No hay modelos de pronóstico disponibles. Instale las bibliotecas requeridas (prophet, statsmodels, sklearn, tensorflow).",
        "lstm_warning1": "Conjunto de datos demasiado pequeño para LSTM. Omitiendo pronóstico LSTM.",
        "lstm_warning2": "No hay suficientes secuencias para el entrenamiento LSTM. Omitiendo LSTM.",
        "language_select": "Seleccione su idioma preferido",
        "city_select": "Seleccione su ciudad en el globo",
        "current_time": "Hora Actual"
    },
    "fr": {
        "disclaimer_title": "AVERTISSEMENT",
        "disclaimer_text": """Point blank fournit des données boursières, des analyses and des outils prédictifs à des **fins éducatives and informatives uniquement**.  

- Point blank **ne fournit pas** de conseils financiers, d'investissement, de trading ou juridiques.  
- Toutes les informations, prévisions and analyses générées par Point blank sont **seulement des estimations** and peuvent être inexactes, incomplètes ou obsolètes.  
- Les investissements boursiers sont intrinsèquement **risqués and volatils**. Les performances passées ne sont pas indicatives des résultats futurs.  
- Les utilisadores sont seuls responsables de toute décision d'investissement ou de trading prise sur la basis du contenu de Point blank.  
- Les développeurs, propriétaires, affiliés and contributeurs de Point blank **ne pourront être tenus responsables** de toute perte financière, dommage ou conséquence découlant directement ou indirectlement de son utilisation.  

En utilisant Point blank, vous reconnaissez que vous comprenez ces risques and acceptez d'utiliser le site Web à vos propres risques and responsabilités.  
Pour des conseils financiers personnalisés, veuillez consulter un conseiller financier agréé.""",
        "accept_disclaimer": "J'ai lu and accepté l'avertissement",
        "title": "POINT.BLANC",
        "ticker_label": "Symbole",
        "period_label": "Période historique",
        "interval_label": "Intervalle",
        "indicators_label": "Afficher les indicateurs",
        "run_button": "Tout exécuter",
        "fetching_data": "Récupération des données boursières and calcul des indicateurs...",
        "no_data": "Aucune donnée récupérée. Vérifiez le symbole ou la connexion réseau.",
        "price_chart": "Graphique des prix and indicateurs techniques",
        "ai_forecasts": "Prévisions IA",
        "running_models": "Exécution des modèles de prévision...",
        "news": "ACTUALITÉS",
        "fetching_news": "Récupération des dernières actualités...",
        "no_articles": "Aucun article récent trouvé.",
        "export_data": "Exporter les données",
        "download_csv": "Télécharger les données brutes (CSV)",
        "download_json": "Télécharger les données historiques (JSON)",
        "download_news": "Télécharger les données d'actualités (CSV)",
        "recent_data": "Données historiques récentes",
        "select_ticker": "Sélectionnez un symbole and appuyez sur **'Exécuter'** pour obtenir une analyse complète des actions avec prévisions and actualités !",
        "model_status": "État de disponibilité du modèle",
        "available": "Disponible",
        "missing": "Manquant",
        "date": "Date",
        "open": "Ouverture",
        "high": "Haut",
        "low": "Bas",
        "close": "Clôture",
        "prophet": "Prophète",
        "arima": "ARIMA",
        "random_forest": "Forêt Aléatoire",
        "lstm": "LSTM",
        "historical": "Historique",
        "forecast": "Prévision",
        "lower_bound": "Limite inférieure",
        "upper_bound": "Limite supérieure",
        "download": "Télécharger",
        "warning": "Veuillez accepté l'avertissement pour utiliser l'application.",
        "error_fetching": "Erreur lors de la récupération des données",
        "error_computing": "Erreur lors du calcul des indicateurs",
        "error_chart": "Erreur lors de la création du graphique",
        "error_metrics": "Erreur lors de l'affichage des métriques",
        "error_forecasts": "Erreur lors de l'affichage des prévisions",
        "error_news": "Erreur lors de l'affichage des actualités",
        "error_export": "Erreur lors de la création de la section d'exportation",
        "prophet_error": "Erreur de Prophète amélioré",
        "arima_error": "Erreur ARIMA",
        "rf_error": "Erreur de Forêt Aléatoire",
        "lstm_error": "Erreur LSTM améliorée",
        "no_models": "Aucun modèle de prévision disponible. Installez les bibliothèques requises (prophet, statsmodels, sklearn, tensorflow).",
        "lstm_warning1": "Jeu de données trop petit pour LSTM. Ignorer la prévision LSTM.",
        "lstm_warning2": "Pas assez de séquences pour l'entraînement LSTM. Ignorer LSTM.",
        "language_select": "Sélectionnez votre langue préférée",
        "city_select": "Sélectionnez votre ville sur le globe",
        "current_time": "Heure Actuelle"
    },
    "pt": {
        "disclaimer_title": "AVISO LEGAL",
        "disclaimer_text": """Point blank fornece dados do mercado de ações, análises e ferramentas preditivas apenas para **fins educacionais e informativos**.  

- Point blank **não** fornece aconselhamento financeiro, de investimento, de negociação ou jurídico.  
- Todas as informações, previsões e análises geradas pelo Point blank são **apenas estimativas** e podem ser imprecisas, incompletas ou desatualizadas.  
- Investimentos no mercado de ações são inerentemente **arriscados e voláteis**. O desempenho passado não é indicativo de resultados futuros.  
- Os usuários são os únicos responsáveis por quaisquer decisões de investimento ou negociação tomadas com base no conteúdo do Point blank.  
- Os desenvolvedores, proprietários, afiliados e colaboradores do Point blank **não serão responsabilizados** por quaisquer perdas financeiras, danos ou consequências decorrentes direta ou indiretamente de seu uso.  

Ao usar o Point blank, você reconhece que entende esses riscos e concorda em usar o site por sua própria conta e risco.  
Para orientação financiera personalizada, consulte um consultor financeiro licenciado.""",
        "accept_disclaimer": "Eu li e aceito o aviso legal",
        "title": "PONTO.BRANCO",
        "ticker_label": "Ticker",
        "period_label": "Período histórico",
        "interval_label": "Intervalo",
        "indicators_label": "Mostrar indicadores",
        "run_button": "Executar tudo",
        "fetching_data": "Obtendo dados de ações e calculando indicadores...",
        "no_data": "Nenhum dado recuperado. Verifique o ticker ou a conexão de réseau.",
        "price_chart": "Gráfico de preços e indicadores técnicos",
        "ai_forecasts": "Previsões de IA",
        "running_models": "Executando modelos de previsão...",
        "news": "NOTÍCIAS",
        "fetching_news": "Obtendo notícias recentes...",
        "no_articles": "Nenhum artigo recente encontrado.",
        "export_data": "Exportar dados",
        "download_csv": "Baixar dados brutos (CSV)",
        "download_json": "Baixar dados históricos (JSON)",
        "download_news": "Baixar dados de notícias (CSV)",
        "recent_data": "Dados históricos recentes",
        "select_ticker": "Selecione a ticker e pressione **'Executar'** para obter uma análise completa de ações com previsões e notícias!",
        "model_status": "Status de disponibilidade do modelo",
        "available": "Disponível",
        "missing": "Faltando",
        "date": "Data",
        "open": "Abertura",
        "high": "Alta",
        "low": "Baixa",
        "close": "Fechamento",
        "prophet": "Profeta",
        "arima": "ARIMA",
        "random_forest": "Floresta Aleatória",
        "lstm": "LSTM",
        "historical": "Histórico",
        "forecast": "Prevision",
        "lower_bound": "Limite inferior",
        "upper_bound": "Limite superior",
        "download": "Baixar",
        "warning": "Por favor, aceite o aviso legal para usar o aplicativo.",
        "error_fetching": "Erro ao obter dados",
        "error_computing": "Erro ao calcular indicadores",
        "error_chart": "Erro ao criar gráfico",
        "error_metrics": "Erro ao exibir métricas",
        "error_forecasts": "Erro ao exibir previsões",
        "error_news": "Erro ao exibir notícias",
        "error_export": "Erro ao criar seção de exportação",
        "prophet_error": "Erro de Profeta aprimorado",
        "arima_error": "Erro ARIMA",
        "rf_error": "Erro de Floresta Aleatória",
        "lstm_error": "Erro LSTM aprimorado",
        "no_models": "Nenhum modelo de previsão disponível. Instale as bibliotecas necessárias (prophet, statsmodels, sklearn, tensorflow).",
        "lstm_warning1": "Conjunto de dados muito pequeno para LSTM. Ignorando previsão LSTM.",
        "lstm_warning2": "Sequências insuficientes para treinamento LSTM. Ignorando LSTM.",
        "language_select": "Selecione seu idioma preferido",
        "city_select": "Selecione sua cidade no globo",
        "current_time": "Hora Atual"
    },
    "ta": {
        "disclaimer_title": "மறுப்பு விதி",
        "disclaimer_text": """Point blank பங்குச் சந்தை தரவு, பகுப்பாய்வு மற்றும் கணிப்பு கருவிகளை **கல்வி மற்றும் தகவல் நோக்கங்களுக்காக மட்டுமே** வழங்குகிறது.  

- Point blank நிதி, முதலீட்டு, வர்த்தக அல்லது சட்ட ஆலோசனையை **வழங்காது**.  
- Point blank உருவாக்கிய அனைத்து தகவல்கள், கணிப்புகள் மற்றும் பகுப்பாய்வுகள் **வெறும் மதிப்பீடுகள் மட்டுமே** மற்றும் தவறான, முழுமையற்ற அல்லது காலாவதியானதாக இருக்கலாம்.  
- பங்குச் சந்தை முதலீடுகள் இயல்பாகவே **ஆபத்தானவை மற்றும் ஏற்ற இறக்கமுடையவை**. கடந்த செயல்திறன் எதிர்கால முடிவுகளுக்கு அறிகுறியாக இல்லை.  
- Point blank இன் உள்ளடக்கத்தின் அடிப்படையில் எடுக்கப்பட்ட எந்த முதலீட்டு அல்லது வர்த்தக முடிவுகளுக்கும் பயனர்கள் மட்டுமே பொறுப்பு.  
- Point blank இன் உருவாக்குநர்கள், உரிமையாளர்கள், இணை நிறுவனங்கள் மற்றும் பங்களிப்பாளர்கள் அதன் பயன்பாட்டிலிருந்து நேரடியாகவோ அல்லது மறைமுகமாகவோ எழும் எந்த நிதி இழப்புகள், சேதங்கள் அல்லது விளைவுகளுக்கும் **பொறுப்பாக இருக்க மாட்டார்கள்**.  

Point blank ஐப் பயன்படுத்துவதன் மூலம், இந்த அபாயங்களை நீங்கள் புரிந்துகொள்கிறீர்கள் என்பதையும், வலைத்தளத்தை உங்கள் சொந்த விருப்பத்தின்படி மற்றும் பொறுப்புடன் பயன்படுத்த ஒப்புக்கொள்கிறீர்கள் என்பதையும் ஒப்புக்கொள்கிறீர்கள்.  
தனிப்பட்ட நிதி வழிகாட்டுதலுக்கு, தயவுசெய்து உரிமம் பெற்ற நிதி ஆலோசகரை அணுகவும்.""",
        "accept_disclaimer": "நான் மறுப்பு விதியைப் படித்து ஏற்றுக்கொள்கிறேன்",
        "title": "பாயிண்ட்.பிளாங்க்",
        "ticker_label": "டிக்கர்",
        "period_label": "வரலாற்று காலம்",
        "interval_label": "இடைவெளி",
        "indicators_label": "குறிகாட்டிகளைக் காட்டு",
        "run_button": "அனைத்தையும் இயக்கு",
        "fetching_data": "பங்குத் தரவைப் பெறுதல் மற்றும் குறிகாட்டிகளைக் கணக்கிடுகிறது...",
        "no_data": "தரவு பெறப்படவில்லை. டிக்கர் அல்லது நெட்வொர்க் இணைப்பைச் சரிபார்க்கவும்.",
        "price_chart": "விலை விளக்கப்படம் & தொழில்நுட்ப குறிகாட்டிகள்",
        "ai_forecasts": "AI கணிப்புகள்",
        "running_models": "கணிப்பு மாதிரிகளை இயக்குகிறது...",
        "news": "செய்திகள்",
        "fetching_news": "சமீபத்திய செய்திகளைப் பெறுகிறது...",
        "no_articles": "சமீபத்திய கட்டுரைகள் எதுவும் கிடைக்கவில்லை.",
        "export_data": "தரவை ஏற்றுமதி செய்",
        "download_csv": "மூல தரவைப் பதிவிறக்கு (CSV)",
        "download_json": "வரலாற்றுத் தரவைப் பதிவிறக்கு (JSON)",
        "download_news": "செய்தித் தரவைப் பதிவிறக்கு (CSV)",
        "recent_data": "சமீபத்திய வரலாற்றுத் தரவு",
        "select_ticker": "ஒரு டிக்கரைத் தேர்ந்தெடுத்து **'இயக்கு'** என்பதை அழுத்துங்கள், கணிப்புகள் மற்றும் செய்திகளுடன் முழுமையான பங்கு பகுப்பாய்வைப் பெற!",
        "model_status": "மாதிரி கிடைக்கும் நிலை",
        "available": "கிடைக்கிறது",
        "missing": "காணவில்லை",
        "date": "தேதி",
        "open": "திறப்பு",
        "high": "உயர்",
        "low": "தாழ்",
        "close": "மூடுதல்",
        "prophet": "பிராபெட்",
        "arima": "ARIMA",
        "random_forest": "ரேண்டம் ஃபாரஸ்ட்",
        "lstm": "LSTM",
        "historical": "வரலாற்று",
        "forecast": "கணிப்பு",
        "lower_bound": "கீழ் வரம்பு",
        "upper_bound": "மேல் வரம்பு",
        "download": "பதிவிறக்கம்",
        "warning": "பயன்பாட்டைப் பயன்படுத்த மறுப்பு விதியை ஏற்றுக்கொள்ளவும்.",
        "error_fetching": "தரவைப் பெறுவதில் பிழை",
        "error_computing": "குறிகாட்டிகளைக் கணக்கிடுவதில் பிழை",
        "error_chart": "விளக்கப்படத்தை உருவாக்குவதில் பிழை",
        "error_metrics": "அளவீடுகளைக் காண்பிப்பதில் பிழை",
        "error_forecasts": "கணிப்புகளைக் காண்பிப்பதில் பிழை",
        "error_news": "செய்திகளைக் காண்பிப்பதில் பிழை",
        "error_export": "ஏற்றுமதி பிரிவை உருவாக்குவதில் பிழை",
        "prophet_error": "மேம்படுத்தப்பட்ட பிராபெட் பிழை",
        "arima_error": "ARIMA பிழை",
        "rf_error": "ரேண்டம் ஃபாரஸ்ட் பிழை",
        "lstm_error": "மேம்படுத்தப்பட்ட LSTM பிழை",
        "no_models": "கணிப்பு மாதிரிகள் எதுவும் கிடைக்கவில்லை. தேவையான நூலகங்களை நிறுவவும் (prophet, statsmodels, sklearn, tensorflow).",
        "lstm_warning1": "LSTM க்கு தரவுத் தொகுப்பு மிகச் சிறியது. LSTM கணிப்பைத் தவிர்க்கிறது.",
        "lstm_warning2": "LSTM பயிற்சிக்கு போதுமான வரிசைகள் இல்லை. LSTM ஐத் தவிர்க்கிறது.",
        "language_select": "உங்களுக்கு விருப்பமான மொழியைத் தேர்ந்தெடுக்கவும்",
        "city_select": "கோளத்தில் உங்கள் நகரத்தைத் தேர்ந்தெடுக்கவும்",
        "current_time": "தற்போதைய நேரம்"
    }
}

# Language mapping for cities
city_languages = {
    "New York": {"languages": ["en", "ta"], "default": "en"},
    "Toronto": {"languages": ["en", "fr", "ta"], "default": "en"},
    "Mexico City": {"languages": ["es", "ta"], "default": "es"},
    "São Paulo": {"languages": ["pt", "ta"], "default": "pt"},
    "Buenos Aires": {"languages": ["es", "ta"], "default": "es"},
    "Santiago": {"languages": ["es", "ta"], "default": "es"},
    "Lima": {"languages": ["es", "ta"], "default": "es"},
    "Bogotá": {"languages": ["es", "ta"], "default": "es"},
    "London": {"languages": ["en", "ta"], "default": "en"},
    "Paris": {"languages": ["fr", "ta"], "default": "fr"},
    "Frankfurt": {"languages": ["de", "ta"], "default": "de"},
    "Milan": {"languages": ["it", "ta"], "default": "it"},
    "Rome": {"languages": ["it", "ta"], "default": "it"},
    "Madrid": {"languages": ["es", "ta"], "default": "es"},
    "Dublin": {"languages": ["en", "ta"], "default": "en"},
    "Athens": {"languages": ["el", "ta"], "default": "el"},
    "Helsinki": {"languages": ["fi", "sv", "ta"], "default": "fi"},
    "Warsaw": {"languages": ["pl", "ta"], "default": "pl"},
    "Istanbul": {"languages": ["tr", "ta"], "default": "tr"},
    "Cairo": {"languages": ["ar", "ta"], "default": "ar"},
    "Johannesburg": {"languages": ["en", "zu", "xh", "af", "nso", "tn", "st", "ts", "ss", "ve", "nr", "ta"], "default": "en"},
    "Nairobi": {"languages": ["en", "sw", "ta"], "default": "en"},
    "Lagos": {"languages": ["en", "ha", "yo", "ig", "ta"], "default": "en"},
    "Casablanca": {"languages": ["ar", "ber", "ta"], "default": "ar"},
    "Dubai": {"languages": ["ar", "ta"], "default": "ar"},
    "Tel Aviv": {"languages": ["he", "ar", "ta"], "default": "he"},
    "Amman": {"languages": ["ar", "ta"], "default": "ar"},
    "Karachi": {"languages": ["ur", "en", "ta"], "default": "ur"},
    "Delhi": {"languages": ["hi", "en", "ta"], "default": "hi"},
    "Kathmandu": {"languages": ["ne", "ta"], "default": "ne"},
    "Dhaka": {"languages": ["bn", "ta"], "default": "bn"},
    "Colombo": {"languages": ["si", "ta"], "default": "si"},
    "Bangkok": {"languages": ["th", "ta"], "default": "th"},
    "Singapore": {"languages": ["en", "ms", "zh", "ta"], "default": "en"},
    "Kuala Lumpur": {"languages": ["ms", "ta"], "default": "ms"},
    "Jakarta": {"languages": ["id", "ta"], "default": "id"},
    "Shanghai": {"languages": ["zh", "ta"], "default": "zh"},
    "Taipei": {"languages": ["zh", "ta"], "default": "zh"},
    "Tokyo": {"languages": ["ja", "ta"], "default": "ja"},
    "Seoul": {"languages": ["ko", "ta"], "default": "ko"},
    "Almaty": {"languages": ["kk", "ru", "ta"], "default": "kk"},
    "Tashkent": {"languages": ["uz", "ta"], "default": "uz"},
    "Ulaanbaatar": {"languages": ["mn", "ta"], "default": "mn"},
    "Yangon": {"languages": ["my", "ta"], "default": "my"},
    "Sydney": {"languages": ["en", "ta"], "default": "en"},
    "Melbourne": {"languages": ["en", "ta"], "default": "en"},
    "Auckland": {"languages": ["en", "mi", "ta"], "default": "en"},
}

# Language names for display
language_names = {
    "en": "English",
    "es": "Español",
    "fr": "Français",
    "pt": "Português",
    "ta": "தமிழ்",
    "de": "Deutsch",
    "it": "Italiano",
    "el": "Ελληνικά",
    "fi": "Suomi",
    "sv": "Svenska",
    "pl": "Polski",
    "tr": "Türkçe",
    "ar": "العربية",
    "zu": "Zulu",
    "xh": "Xhosa",
    "af": "Afrikaans",
    "nso": "Northern Sotho",
    "tn": "Tswana",
    "st": "Southern Sotho",
    "ts": "Tsonga",
    "ss": "Swati",
    "ve": "Venda",
    "nr": "Ndebele",
    "sw": "Swahili",
    "ber": "Berber",
    "he": "עברית",
    "ur": "Urdu",
    "hi": "Hindi",
    "ne": "Nepali",
    "bn": "Bengali",
    "si": "Sinhala",
    "th": "ไทย",
    "ms": "Malay",
    "id": "Indonesian",
    "zh": "中文",
    "ja": "日本語",
    "ko": "한국어",
    "kk": "Kazakh",
    "ru": "Russian",
    "uz": "Uzbek",
    "mn": "Mongolian",
    "my": "Burmese",
    "mi": "Māori"
}

# For languages without translations, copy from English
for lang_code in translations:
    if not translations[lang_code]:
        translations[lang_code] = translations["en"].copy()

# Function to get translation
def tr(key, lang="en"):
    return translations.get(lang, translations["en"]).get(key, key)

# ------------------------------
# Expanded City list with timezones (covering all major zones)
# ------------------------------
cities = [
    # Pacific & Americas
    {"city": "Honolulu", "lat": 21.3069, "lon": -157.8583, "timezone": "Pacific/Honolulu"},
    {"city": "Anchorage", "lat": 61.2181, "lon": -149.9003, "timezone": "America/Anchorage"},
    {"city": "Los Angeles", "lat": 34.0522, "lon": -118.2437, "timezone": "America/Los_Angeles"},
    {"city": "Denver", "lat": 39.7392, "lon": -104.9903, "timezone": "America/Denver"},
    {"city": "Chicago", "lat": 41.8781, "lon": -87.6298, "timezone": "America/Chicago"},
    {"city": "New York", "lat": 40.7128, "lon": -74.0060, "timezone": "America/New_York"},
    {"city": "Toronto", "lat": 43.6532, "lon": -79.3832, "timezone": "America/Toronto"},
    {"city": "Mexico City", "lat": 19.4326, "lon": -99.1332, "timezone": "America/Mexico_City"},
    {"city": "São Paulo", "lat": -23.5505, "lon": -46.6333, "timezone": "America/Sao_Paulo"},
    {"city": "Buenos Aires", "lat": -34.6037, "lon": -58.3816, "timezone": "America/Argentina/Buenos_Aires"},
    {"city": "Santiago", "lat": -33.4489, "lon": -70.6693, "timezone": "America/Santiago"},
    {"city": "Lima", "lat": -12.0464, "lon": -77.0428, "timezone": "America/Lima"},
    {"city": "Caracas", "lat": 10.4806, "lon": -66.9036, "timezone": "America/Caracas"},
    {"city": "Bogotá", "lat": 4.7110, "lon": -74.0721, "timezone": "America/Bogota"},
    {"city": "Phoenix", "lat": 33.4484, "lon": -112.0740, "timezone": "America/Phoenix"},
    {"city": "Adak", "lat": 51.8780, "lon": -176.6581, "timezone": "America/Adak"},

    # Europe & Africa
    {"city": "London", "lat": 51.5074, "lon": -0.1278, "timezone": "Europe/London"},
    {"city": "Lisbon", "lat": 38.7169, "lon": -9.1390, "timezone": "Europe/Lisbon"},
    {"city": "Paris", "lat": 48.8566, "lon": 2.3522, "timezone": "Europe/Paris"},
    {"city": "Berlin", "lat": 52.5200, "lon": 13.4050, "timezone": "Europe/Berlin"},
    {"city": "Rome", "lat": 41.9028, "lon": 12.4964, "timezone": "Europe/Rome"},
    {"city": "Madrid", "lat": 40.4168, "lon": -3.7038, "timezone": "Europe/Madrid"},
    {"city": "Dublin", "lat": 53.3331, "lon": -6.2489, "timezone": "Europe/Dublin"},
    {"city": "Athens", "lat": 37.9838, "lon": 23.7275, "timezone": "Europe/Athens"},
    {"city": "Helsinki", "lat": 60.1699, "lon": 24.9384, "timezone": "Europe/Helsinki"},
    {"city": "Warsaw", "lat": 52.2297, "lon": 21.0122, "timezone": "Europe/Warsaw"},
    {"city": "Moscow", "lat": 55.7558, "lon": 37.6173, "timezone": "Europe/Moscow"},
    {"city": "Istanbul", "lat": 41.0082, "lon": 28.9784, "timezone": "Europe/Istanbul"},
    {"city": "Cairo", "lat": 30.0444, "lon": 31.2357, "timezone": "Africa/Cairo"},
    {"city": "Johannesburg", "lat": -26.2041, "lon": 28.0473, "timezone": "Africa/Johannesburg"},
    {"city": "Nairobi", "lat": -1.2921, "lon": 36.8219, "timezone": "Africa/Nairobi"},
    {"city": "Lagos", "lat": 6.5244, "lon": 3.3792, "timezone": "Africa/Lagos"},
    {"city": "Casablanca", "lat": 33.5731, "lon": -7.5898, "timezone": "Africa/Casablanca"},

    # Middle East & Asia
    {"city": "Dubai", "lat": 25.276987, "lon": 55.296249, "timezone": "Asia/Dubai"},
    {"city": "Tehran", "lat": 35.6892, "lon": 51.3890, "timezone": "Asia/Tehran"},
    {"city": "Jerusalem", "lat": 31.7683, "lon": 35.2137, "timezone": "Asia/Jerusalem"},
    {"city": "Amman", "lat": 31.9497, "lon": 35.9323, "timezone": "Asia/Amman"},
    {"city": "Karachi", "lat": 24.8607, "lon": 67.0011, "timezone": "Asia/Karachi"},
    {"city": "Delhi", "lat": 28.6139, "lon": 77.2090, "timezone": "Asia/Kolkata"},
    {"city": "Kathmandu", "lat": 27.7172, "lon": 85.3240, "timezone": "Asia/Kathmandu"},
    {"city": "Dhaka", "lat": 23.8103, "lon": 90.4125, "timezone": "Asia/Dhaka"},
    {"city": "Colombo", "lat": 6.9271, "lon": 79.8612, "timezone": "Asia/Colombo"},
    {"city": "Bangkok", "lat": 13.7563, "lon": 100.5018, "timezone": "Asia/Bangkok"},
    {"city": "Singapore", "lat": 1.3521, "lon": 103.8198, "timezone": "Asia/Singapore"},
    {"city": "Kuala Lumpur", "lat": 3.1390, "lon": 101.6869, "timezone": "Asia/Kuala_Lumpur"},
    {"city": "Jakarta", "lat": -6.2088, "lon": 106.8456, "timezone": "Asia/Jakarta"},
    {"city": "Shanghai", "lat": 31.2304, "lon": 121.4737, "timezone": "Asia/Shanghai"},
    {"city": "Taipei", "lat": 25.0330, "lon": 121.5654, "timezone": "Asia/Taipei"},
    {"city": "Tokyo", "lat": 35.6762, "lon": 139.6503, "timezone": "Asia/Tokyo"},
    {"city": "Seoul", "lat": 37.5665, "lon": 126.9780, "timezone": "Asia/Seoul"},
    {"city": "Almaty", "lat": 43.2220, "lon": 76.8512, "timezone": "Asia/Almaty"},
    {"city": "Tashkent", "lat": 41.2995, "lon": 69.2401, "timezone": "Asia/Tashkent"},
    {"city": "Ulaanbaatar", "lat": 47.8864, "lon": 106.9057, "timezone": "Asia/Ulaanbaatar"},
    {"city": "Yangon", "lat": 16.8409, "lon": 96.1735, "timezone": "Asia/Yangon"},

    # Oceania
    {"city": "Sydney", "lat": -33.8688, "lon": 151.2093, "timezone": "Australia/Sydney"},
    {"city": "Melbourne", "lat": -37.8136, "lon": 144.9631, "timezone": "Australia/Melbourne"},
    {"city": "Brisbane", "lat": -27.4698, "lon": 153.0251, "timezone": "Australia/Brisbane"},
    {"city": "Adelaide", "lat": -34.9285, "lon": 138.6007, "timezone": "Australia/Adelaide"},
    {"city": "Perth", "lat": -31.9505, "lon": 115.8605, "timezone": "Australia/Perth"},
    {"city": "Auckland", "lat": -36.8485, "lon": 174.7633, "timezone": "Pacific/Auckland"},
    {"city": "Fiji", "lat": -18.1416, "lon": 178.4419, "timezone": "Pacific/Fiji"},
    {"city": "Noumea", "lat": -22.2763, "lon": 166.4572, "timezone": "Pacific/Noumea"},
    {"city": "Guadalcanal", "lat": -9.4456, "lon": 160.1960, "timezone": "Pacific/Guadalcanal"},
]

# ------------------------------
# Session state initialization
# ------------------------------
if "selected_city_index" not in st.session_state:
    st.session_state.selected_city_index = 0

if "accepted_disclaimer" not in st.session_state:
    st.session_state.accepted_disclaimer = False

if "user_lang" not in st.session_state:
    st.session_state.user_lang = "en"

# ------------------------------
# Prepare ScatterGeo figure
# ------------------------------
st.markdown(f"### {tr('city_select', st.session_state.user_lang)}")

lons = [c["lon"] for c in cities]
lats = [c["lat"] for c in cities]
texts = [c["city"] for c in cities]

fig = go.Figure(go.Scattergeo(
    lon=lons,
    lat=lats,
    mode="markers+text",
    text=texts,
    textposition="top center",
    marker=dict(size=7, color="red", symbol="circle")
))

fig.update_geos(
    projection_type="orthographic",
    showland=True,
    landcolor="rgb(255, 255, 255)",
    showcountries=True,
    countrycolor="black",
    showocean=True,
    oceancolor="rgb(255, 255, 255)",
    showcoastlines=True,
    coastlinecolor="black",
    showframe=False,
    showlakes=False,
    showrivers=False,
    lonaxis=dict(showgrid=True, gridcolor="lightgray", dtick=30),
    lataxis=dict(showgrid=True, gridcolor="lightgray", dtick=15),
)

fig.update_layout(
    geo=dict(projection_scale=0.6, center=dict(lat=0, lon=0)),
    margin={"r":0,"t":0,"l":0,"b":0},
    paper_bgcolor="white",
    font_color="black"
)

# Show the globe (only click selection)
clicked_points = plotly_events(fig, click_event=True, hover_event=False)

if clicked_points:
    st.session_state.selected_city_index = clicked_points[0]["pointNumber"]

selected_city = cities[st.session_state.selected_city_index]

# ------------------------------
# Language selection
# ------------------------------
city_name = selected_city["city"]
city_langs_info = city_languages.get(city_name, {"languages": ["en","ta"], "default": "en"})
available_lang_codes = list(dict.fromkeys(["en", "ta"] + city_langs_info.get("languages", [])))
default_lang = city_langs_info.get("default", "en")

lang_options = [(code, language_names.get(code, code)) for code in available_lang_codes]
select_display = [f"{code} — {language_names.get(code, code)}" for code in available_lang_codes]

st.markdown(f"### {tr('language_select', st.session_state.user_lang)}")
chosen_display = st.selectbox("", options=select_display, index=available_lang_codes.index(st.session_state.user_lang))
chosen_code = chosen_display.split(" — ")[0].strip()
if chosen_code != st.session_state.user_lang:
    st.session_state.user_lang = chosen_code

# ------------------------------
# Digital live clock
# ------------------------------
tz = pytz.timezone(selected_city["timezone"])
current_time = datetime.now(tz).strftime("%I:%M:%S %p")

st.markdown(
    f"""
    <div style="font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Display', 'Helvetica Neue', Arial, sans-serif;
                font-size: 36px; font-weight: 600; color: white;">
        {tr('current_time', st.session_state.user_lang)} — {selected_city['city']}: {current_time}
    </div>
    """,
    unsafe_allow_html=True
)

# --------------------------
# Disclaimer Gate
# --------------------------
st.markdown("---")
st.markdown(f"## {tr('disclaimer_title', st.session_state.user_lang)}")
st.markdown(tr('disclaimer_text', st.session_state.user_lang), unsafe_allow_html=True)

accept = st.checkbox(tr('accept_disclaimer', st.session_state.user_lang))
if accept:
    st.session_state.accepted_disclaimer = True
else:
    st.session_state.accepted_disclaimer = False
    st.warning(tr('warning', st.session_state.user_lang))
    st.stop()

# --------------------------
# Streamlit page config + CSS
# --------------------------
st.set_page_config(page_title=tr("title", st.session_state.user_lang), layout="wide")

st.markdown("""
<style>
:root {
    --bg: #000000;
    --card: #1C1C1E;
    --muted: #8E8E93;
    --accent: #0A84FF;
    --border: #38383A;
    --text: #FFFFFF;
    --secondary-text: #EBEBF599;
}

body, .stApp {
    background-color: var(--bg);
    color: var(--text);
    font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Display', 'Helvetica Neue', sans-serif;
}

.block-container {
    padding-top: 1rem;
    max-width: 1150px;
    margin-left: auto;
    margin-right: auto;
}

.stButton>button {
    background-color: var(--card);
    color: var(--text);
    border-radius: 12px;
    border: 1px solid var(--border);
    padding: 0.55em 1em;
    font-weight: 500;
}

.stTextInput>div>div>input, .stSelectbox>div>div, .stSlider>div>div {
    background-color: var(--card);
    color: var(--text);
    border-radius: 10px;
    border: 1px solid var(--border);
    padding: 0.5rem;
}

.stCheckbox>div, .stRadio>div {
    color: var(--text);
}

h1, h2, h3, h4 {
    color: var(--text);
    text-align: center;
    font-weight: 600;
}

.model-availability {
    background-color: var(--card);
    padding: 12px;
    border-radius: 12px;
    border: 1px solid var(--border);
}

.news-list {
    margin-top: 12px;
}

a.card-link {
    text-decoration: none;
    color: inherit;
    display: block;
}

.news-card {
    background: var(--card);
    border: 1px solid var(--border);
    border-radius: 14px;
    padding: 16px;
    margin-bottom: 12px;
    display: flex;
    gap: 16px;
    align-items: flex-start;
    transition: all 0.2s ease;
}

.news-card:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 16px rgba(0,0,0,0.3);
}

.news-img {
    width: 100px;
    height: 70px;
    object-fit: cover;
    border-radius: 8px;
    flex-shrink: 0;
    background: #2C2C2E;
}

.news-content {
    flex: 1;
    min-width: 0;
}

.news-title {
    font-weight: 600;
    color: var(--text);
    font-size: 16px;
    line-height: 1.4;
    margin-bottom: 6px;
    overflow-wrap: anywhere;
}

.news-meta {
    font-size: 13px;
    color: var(--muted);
}

.empty {
    color: var(--muted);
    padding: 16px;
    border-radius: 12px;
    background: var(--card);
    border: 1px solid var(--border);
    text-align: center;
}

[data-testid="stMetric"] {
    background-color: var(--card);
    border: 1px solid var(--border);
    border-radius: 12px;
    padding: 16px;
}

[data-testid="stMetricLabel"] {
    color: var(--muted);
    font-size: 14px;
}

[data-testid="stMetricValue"] {
    color: var(--text);
    font-size: 24px;
    font-weight: 600;
}

.stSelectbox div[data-baseweb="select"] {
    background-color: var(--card);
    border-radius: 10px;
}

.stSelectbox div[data-baseweb="select"] div {
    color: var(--text);
}

.streamlit-expanderHeader {
    background-color: var(--card);
    border-radius: 10px;
    border: 1px solid var(--border);
    font-weight: 600;
}

.streamlit-expanderContent {
    background-color: var(--card);
    border-radius: 0 0 10px 10px;
    border: 1px solid var(--border);
    border-top: none;
}
</style>
""", unsafe_allow_html=True)

# --------------------------
# Data fetching and processing functions
# --------------------------
@st.cache_data(ttl=300)
def fetch_yahoo_data(ticker: str, period="6mo", interval="1d") -> pd.DataFrame:
    try:
        t = yf.Ticker(ticker)
        df = t.history(period=period, interval=interval)
        if df is None or df.empty:
            return pd.DataFrame()
        df = df.reset_index()
        df['Date'] = pd.to_datetime(df['Date'])
        try:
            df['Date'] = df['Date'].dt.tz_localize(None)
        except Exception:
            df['Date'] = pd.to_datetime(df['Date']).dt.tz_localize(None)
        for col in ['Open','High','Low','Close','Volume']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        df = df.dropna(subset=['Date','Close']).reset_index(drop=True)
        return df
    except Exception:
        return pd.DataFrame()

def compute_indicators(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy().reset_index(drop=True)
    df['MA20'] = df['Close'].rolling(20).mean()
    df['MA50'] = df['Close'].rolling(50).mean()
    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = df['EMA12'] - df['EMA26']
    df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
    df['BB_MID'] = df['Close'].rolling(20).mean()
    df['BB_STD'] = df['Close'].rolling(20).std(ddof=0).fillna(0)
    df['BB_UP'] = df['BB_MID'] + 2*df['BB_STD']
    df['BB_LOW'] = df['BB_MID'] - 2*df['BB_STD']
    delta = df['Close'].diff()
    up = delta.clip(lower=0)
    down = -delta.clip(upper=0)
    roll_up = up.rolling(14).mean()
    roll_down = down.rolling(14).mean()
    rs = roll_up / (roll_down + 1e-8)
    df['RSI'] = 100 - (100 / (1 + rs))
    df['RSI'] = df['RSI'].clip(0,100).fillna(50)
    return df

def plot_advanced(df: pd.DataFrame, title: str, show_indicators: bool = True):
    fig = make_subplots(rows=3, cols=1, shared_xaxes=True,
                        row_heights=[0.6,0.18,0.22],
                        vertical_spacing=0.03)
    fig.add_trace(go.Candlestick(x=df['Date'], open=df['Open'], high=df['High'],
                                 low=df['Low'], close=df['Close'], name='Price'), row=1, col=1)
    if show_indicators:
        fig.add_trace(go.Scatter(x=df['Date'], y=df['MA20'], name='MA20', line=dict(width=1.4)), row=1, col=1)
        fig.add_trace(go.Scatter(x=df['Date'], y=df['MA50'], name='MA50', line=dict(width=1.4, dash='dash')), row=1, col=1)
        fig.add_trace(go.Scatter(x=df['Date'], y=df['BB_UP'], name='BB_UP', line=dict(width=1, dash='dot')), row=1, col=1)
        fig.add_trace(go.Scatter(x=df['Date'], y=df['BB_LOW'], name='BB_LOW', line=dict(width=1, dash='dot')), row=1, col=1)
    fig.add_trace(go.Bar(x=df['Date'], y=df['Volume'], name='Volume', marker_color='gray', opacity=0.3), row=2, col=1)
    fig.add_trace(go.Scatter(x=df['Date'], y=df['RSI'], name='RSI', line=dict(width=1.2)), row=3, col=1)
    fig.add_hline(y=70, line_dash='dot', row=3, col=1)
    fig.add_hline(y=30, line_dash='dot', row=3, col=1)
    fig.update_layout(template='plotly_dark', title=title,
                      margin=dict(l=20,r=20,t=40,b=10),
                      paper_bgcolor='#000000', plot_bgcolor='#000000',
                      legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1))
    st.plotly_chart(fig, use_container_width=True, theme=None)

# --------------------------
# Currency formatting function
# --------------------------
def format_currency(value, currency_code="USD"):
    """Format currency values based on currency code"""
    if pd.isna(value):
        return "N/A"
    
    try:
        # For major currencies, use appropriate symbols
        if currency_code == "USD":
            return f"${value:,.2f}"
        elif currency_code == "EUR":
            return f"€{value:,.2f}"
        elif currency_code == "GBP":
            return f"£{value:,.2f}"
        elif currency_code == "JPY":
            return f"¥{value:,.0f}"
        elif currency_code == "CNY":
            return f"¥{value:,.2f}"
        elif currency_code == "INR":
            return f"₹{value:,.2f}"
        elif currency_code == "CAD":
            return f"C${value:,.2f}"
        elif currency_code == "AUD":
            return f"A${value:,.2f}"
        elif currency_code == "CHF":
            return f"CHF {value:,.2f}"
        elif currency_code == "BTC" or currency_code == "ETH":
            return f"{value:,.6f}"
        else:
            # For other currencies, use code + value
            return f"{currency_code} {value:,.2f}"
    except:
        return f"{value:,.2f}"

# --------------------------
# Get currency information
# --------------------------
@st.cache_data(ttl=3600)
def get_currency_info(ticker: str):
    """Get currency information for a ticker"""
    try:
        info = yf.Ticker(ticker).info
        currency = info.get("currency", "USD")
        market = info.get("market", "us_market")
        return currency, market
    except:
        return "USD", "us_market"

# --------------------------
# Forecasting Models
# --------------------------
def forecast_all(df: pd.DataFrame, periods: int = 30):
    forecasts = {}

    # ==============================
    # Enhanced Prophet
    # ==============================
    if HAS_PROPHET:
        try:
            prophet_df = df[['Date', 'Close']].rename(columns={'Date': 'ds', 'Close': 'y'}).copy()
            prophet_df['ds'] = pd.to_datetime(prophet_df['ds']).dt.tz_localize(None)

            # Dynamic changepoint scale (more flexible if volatile)
            vol = prophet_df['y'].pct_change().std()
            changepoint_scale = 0.05 if vol < 0.02 else 0.2

            m = Prophet(
                growth='linear',
                daily_seasonality=True,
                weekly_seasonality=True,
                yearly_seasonality=True,
                seasonality_mode='multiplicative',
                changepoint_prior_scale=changepoint_scale,
                seasonality_prior_scale=15.0,
                holidays_prior_scale=15.0,
                interval_width=0.95,
                uncertainty_samples=1000
            )

            # Add custom seasonalities
            m.add_seasonality(name='monthly', period=30.5, fourier_order=8)
            m.add_seasonality(name='quarterly', period=91.25, fourier_order=10)

            # Add known regressors
            for col in ['Volume', 'RSI', 'MACD', 'MA20', 'MA50']:
                if col in df.columns:
                    prophet_df[col.lower()] = df[col].fillna(df[col].mean())
                    m.add_regressor(col.lower())

            m.fit(prophet_df)

            # Future DataFrame
            future = m.make_future_dataframe(periods=periods, freq='D')
            future['ds'] = pd.to_datetime(future['ds']).dt.tz_localize(None)

            for col in ['volume', 'rsi', 'macd', 'ma20', 'ma50']:
                if col in prophet_df.columns:
                    last_val = prophet_df[col].iloc[-1]
                    future[col] = last_val

            forecast = m.predict(future)
            fc = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].rename(columns={'ds': 'Date'})
            forecasts['Prophet'] = fc

        except Exception as e:
            st.error(f"{tr('prophet_error', st.session_state.user_lang)}: {e}")

    # ==============================
    # ARIMA Forecast
    # ==============================
    if HAS_ARIMA:
        try:
            series = df.set_index('Date')['Close'].sort_index()
            series.index = pd.to_datetime(series.index).tz_localize(None)

            # Fill missing dates
            daily_idx = pd.date_range(series.index.min(), series.index.max(), freq='D')
            series = series.reindex(daily_idx).ffill().bfill()  # forward & backward fill

            # Automatic order selection if dataset is large enough
            try:
                # Use simple ARIMA if dataset is small
                order = (5, 1, 0) if len(series) < 500 else None
                if order is None:
                    import pmdarima as pm
                    model = pm.auto_arima(series, seasonal=False, stepwise=True, suppress_warnings=True, max_p=10, max_q=10)
                    order = model.order
            except Exception:
                order = (5, 1, 0)  # fallback

            model = ARIMA(series, order=order).fit()
            fc = model.forecast(steps=periods)
            dates = pd.date_range(start=series.index[-1] + timedelta(days=1), periods=periods)
            forecasts['ARIMA'] = pd.DataFrame({'Date': dates, 'yhat': fc.values})

        except Exception as e:
            st.error(f"{tr('arima_error', st.session_state.user_lang)}: {e}")

    # ==============================
    # RandomForest Forecast
    # ==============================
    if HAS_SKLEARN:
        try:
            data = df[['Close']].copy()
            n_lags = min(10, len(data)//2)  # dynamic lag selection for small datasets

            for lag in range(1, n_lags+1):
                data[f'lag_{lag}'] = data['Close'].shift(lag)
            data = data.dropna()

            X = data[[f'lag_{i}' for i in range(1, n_lags+1)]].values
            y = data['Close'].values

            model = RandomForestRegressor(n_estimators=500, max_depth=None, random_state=42, n_jobs=-1)
            model.fit(X, y)

            # Iterative multi-step forecast
            last_window = X[-1].tolist()
            preds = []
            for _ in range(periods):
                p = float(model.predict([last_window]))
                preds.append(p)
                last_window = [p] + last_window[:-1]

            dates = pd.date_range(start=df['Date'].iloc[-1] + timedelta(days=1), periods=periods)
            forecasts['RandomForest'] = pd.DataFrame({'Date': dates, 'yhat': preds})

        except Exception as e:
            st.error(f"{tr('rf_error', st.session_state.user_lang)}: {e}")

    # ==============================
    # Enhanced LSTM
    # ==============================
    if HAS_TF and HAS_SKLEARN:
        try:
            features_df = df.copy()
            feature_cols = ['Close', 'Volume', 'High', 'Low', 'Open']
            extra_cols = ['RSI', 'MACD', 'MA20', 'MA50']
            feature_cols.extend([c for c in extra_cols if c in df.columns])

            feature_data = features_df[feature_cols].fillna(method='ffill').fillna(method='bfill')

            scaler = MinMaxScaler()
            scaled_data = scaler.fit_transform(feature_data)

            # Adjust sequence length for small datasets
            default_sequence_length = 60
            sequence_length = min(default_sequence_length, len(scaled_data) // 2)
            if sequence_length < 10:
                st.warning(tr('lstm_warning1', st.session_state.user_lang))
                forecasts['LSTM'] = None
            else:
                X_sequences, y_sequences = [], []

                for i in range(sequence_length, len(scaled_data)):
                    X_sequences.append(scaled_data[i - sequence_length:i])
                    y_sequences.append(scaled_data[i, 0])  # Close price

                X_sequences, y_sequences = np.array(X_sequences), np.array(y_sequences)

                # Skip if still too few sequences
                if len(X_sequences) < 50:
                    st.warning(tr('lstm_warning2', st.session_state.user_lang))
                    forecasts['LSTM'] = None
                else:
                    # Train-test split
                    train_size = int(len(X_sequences) * 0.8)
                    X_train, X_test = X_sequences[:train_size], X_sequences[train_size:]
                    y_train, y_test = y_sequences[:train_size], y_sequences[train_size:]

                    tf.keras.backend.clear_session()

                    model = Sequential([
                        LSTM(128, return_sequences=True, input_shape=(sequence_length, len(feature_cols))),
                        Dropout(0.3),
                        BatchNormalization(),

                        Bidirectional(LSTM(64, return_sequences=True)),
                        Dropout(0.3),
                        BatchNormalization(),

                        LSTM(32, return_sequences=False),
                        Dropout(0.2),

                        Dense(64, activation='relu'),
                        Dense(32, activation='relu'),
                        Dense(1, activation='linear')
                    ])

                    optimizer = optimizers.Adam(learning_rate=0.001)
                    model.compile(
                        optimizer=optimizer,
                        loss=tf.keras.losses.Huber(),
                        metrics=['mae', 'mse']
                    )

                    callbacks_list = [
                        callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
                        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5),
                        callbacks.ModelCheckpoint("best_lstm.h5", save_best_only=True, monitor="val_loss")
                    ]

                    model.fit(
                        X_train, y_train,
                        epochs=100,
                        batch_size=32,
                        validation_data=(X_test, y_test),
                        callbacks=callbacks_list,
                        verbose=0
                    )

                    # Iterative forecasting
                    last_sequence = scaled_data[-sequence_length:]
                    predictions_scaled = []

                    for _ in range(periods):
                        seq_input = last_sequence.reshape(1, sequence_length, len(feature_cols))
                        pred_scaled = float(model.predict(seq_input, verbose=0)[0, 0])
                        predictions_scaled.append(pred_scaled)

                        new_row = last_sequence[-1].copy()
                        new_row[0] = pred_scaled
                        last_sequence = np.vstack([last_sequence[1:], new_row])

                    # Inverse scaling
                    pred_array = np.zeros((periods, len(feature_cols)))
                    pred_array[:, 0] = predictions_scaled
                    for i in range(1, len(feature_cols)):
                        pred_array[:, i] = scaled_data[-1, i]

                    pred_inverse = scaler.inverse_transform(pred_array)
                    predictions = pred_inverse[:, 0].tolist()

                    dates = pd.date_range(start=df['Date'].iloc[-1] + timedelta(days=1), periods=periods)
                    forecasts['LSTM'] = pd.DataFrame({'Date': dates, 'yhat': predictions})

        except Exception as e:
            st.error(f"{tr('lstm_error', st.session_state.user_lang)}: {e}")

    return forecasts

# --------------------------
# News Utilities
# --------------------------
@st.cache_data(ttl=360)
def get_company_name(ticker: str) -> str:
    if not ticker:
        return ""
    try:
        info = yf.Ticker(ticker).info
        return info.get("shortName") or info.get("longName") or ""
    except Exception:
        return ""

def _format_time(entry) -> str:
    try:
        if entry.get("published_parsed"):
            ts = time.mktime(entry.published_parsed)
            return datetime.fromtimestamp(ts).strftime("%a, %d %b %Y %H:%M:%S")
        if entry.get("published"):
            return str(entry.get("published"))
    except Exception:
        pass
    return "Unknown time"

def _extract_image(entry) -> str | None:
    # try common RSS fields
    mc = entry.get("media_content") or entry.get("mediaContents")
    if mc and isinstance(mc, (list, tuple)) and mc:
        first = mc[0]
        if isinstance(first, dict):
            url = first.get("url") or first.get("value")
            if url:
                return url
    mt = entry.get("media_thumbnail")
    if mt and isinstance(mt, (list, tuple)) and mt:
        try:
            return mt[0].get("url")
        except Exception:
            pass
    for l in entry.get("links", []):
        t = l.get("type", "")
        if t and t.startswith("image"):
            return l.get("href")
        if l.get("rel") == "enclosure" and l.get("href"):
            return l.get("href")
    # fallback: parse summary/description <img>
    summary = entry.get("summary", "") or entry.get("description", "")
    m = re.search(r'<img[^>]+src=["\']([^"\']+)["\']', summary or "", re.IGNORECASE)
    if m:
        return m.group(1)
    return None

def _resolve_link(entry, feed) -> str:
    # 1) prefer a non-news.google.com alternate link (links array)
    for l in entry.get("links", []):
        href = l.get("href") or ""
        rel = l.get("rel", "")
        typ = l.get("type", "")
        if href and "news.google.com" not in href and (rel == "alternate" or typ.startswith("text/html") or typ == ""):
            return href
    # 2) look in summary/description for first external href
    summary = entry.get("summary", "") or entry.get("description", "")
    m = re.search(r'href=["\'](https?://[^"\']+)["\']', summary or "", re.IGNORECASE)
    if m:
        href = m.group(1)
        if "news.google.com" not in href:
            return href
    # 3) try extracting 'url=' query param from entry.link (google redirect)
    link = entry.get("link", "") or ""
    if "url=" in link:
        qs = urllib.parse.parse_qs(urllib.parse.urlparse(link).query).get("url")
        if qs:
            candidate = qs[0]
            if candidate and "news.google.com" not in candidate:
                return candidate
    # 4) fallback: entry.link (may be Google News article)
    if link:
        return link
    # 5) feed-level link fallback
    return feed.feed.get("link") or ""

@st.cache_data(ttl=300)
def fetch_google_news(query: str, max_items: int = 8, hl: str = "en-US", gl: str = "US", ceid: str = "US:en"):
    if not query:
        return []
    encoded = urllib.parse.quote_plus(query)
    rss_url = f"https://news.google.com/rss/search?q={encoded}&hl={hl}&gl={gl}&ceid={ceid}"
    feed = feedparser.parse(rss_url)
    entries = feed.entries or []
    items = []
    seen = set()
    for entry in entries:
        try:
            title = html.unescape(entry.get("title", "")).strip() or "(no title)"
            published = _format_time(entry)
            # source
            src = ""
            s = entry.get("source")
            if isinstance(s, dict):
                src = s.get("title", "") or ""
            if not src:
                src = feed.feed.get("title", "") or entry.get("publisher", "") or "Unknown source"
            image = _extract_image(entry)
            link = _resolve_link(entry, feed)
            if not link:
                continue
            # dedupe by resolved link
            if link in seen:
                continue
            seen.add(link)
            items.append({
                "title": title,
                "link": link,
                "published": published,
                "source": src,
                "image": image
            })
            if len(items) >= max_items:
                break
        except Exception:
            continue
    return items

# --------------------------
# Main App
# --------------------------
st.title(tr("title", st.session_state.user_lang))
st.markdown("---")

tickers_list = [
    # 🌎 Americas - Stocks
    "AAPL","MSFT","AMZN","TSLA","JPM",   # New York
    "RY.TO","SHOP.TO","ENB.TO","ABX.TO", # Toronto
    "AMXL.MX","BIMBOA.MX","CEMEXCPO.MX", # Mexico City
    "PETR4.SA","VALE3.SA","ITUB4.SA",    # São Paulo
    "YPFD.BA","GGAL.BA","TEO.BA",        # Buenos Aires
    "CHILE.SN","ENELAM.SN","SQM.SN",     # Santiago
    "BAP.LM","BVN.LM","SCCO.LM",         # Lima
    "CIB","AVAL",                        # Bogotá

    # 🌍 Europe & Africa - Stocks
    "HSBA.L","BP.L","ULVR.L","BARC.L",   # London
    "MC.PA","TTE.PA","AIR.PA","SAN.PA",  # Paris
    "SIE.DE","VOW3.DE","SAP.DE","ALV.DE",# Frankfurt
    "ENI.MI","ISP.MI","RACE.MI",         # Milan/Rome
    "SAN.MC","TEF.MC","IBE.MC",          # Madrid
    "RYA.IR","CRH.IR","KYGA.IR",         # Dublin
    "ETE.AT","HTO.AT",                   # Athens
    "NOKIA.HE","KNEBV.HE","NESTE.HE",    # Helsinki
    "PKO.WA","PKN.WA","KGH.WA",          # Warsaw
    "TCELL.IS","GARAN.IS","AEFES.IS",    # Istanbul
    "COMI.CA","ETEL.CA",                 # Cairo
    "SOLJ.J","NPN.J","AGLJ.J",           # Johannesburg
    "SCOM.NR","EQTY.NR","KCB.NR",        # Nairobi
    "DANGCEM.LG","MTNN.LG","ZENITH.LG",  # Lagos
    "ATW.CS","IAM.CS",                   # Casablanca

    # 🌏 Middle East & Asia - Stocks
    "EMAAR.DU","DIB.DU",                 # Dubai
    "TEVA.TA","LUMI.TA",                 # Tel Aviv
    "ARBK.AM","THBK.AM",                 # Amman
    "OGDC.KA","HBL.KA",                  # Karachi
    "RELIANCE.NS","TCS.NS","INFY.NS","HDFCBANK.NS", # Delhi
    "NTC.NP","NABIL.NP",                 # Kathmandu
    "GP.DH","SQURPHARMA.DH",             # Dhaka
    "JKH.CM","COMB.CM",                  # Colombo
    "PTT.BK","SCC.BK","BBL.BK",          # Bangkok
    "D05.SI","Z74.SI","BN4.SI",          # Singapore
    "MAYBANK.KL","PCHEM.KL","TENAGA.KL", # Kuala Lumpur
    "BBCA.JK","TLKM.JK",                 # Jakarta
    "601398.SS","601857.SS","600104.SS", # Shanghai
    "2330.TW","2317.TW","2454.TW",       # Taipei
    "7203.T","6758.T","9984.T","7974.T", # Tokyo
    "005930.KQ","005380.KQ","000660.KQ", # Seoul
    "KMGZ.KZ","HSBK.KZ",                 # Almaty
    "UZAUTO.UZ",                         # Tashkent
    "APU.MN","TTL.MN",                   # Ulaanbaatar
    "FMI.MM","MTSH.MM",                  # Yangon

    # 🌊 Oceania - Stocks
    "BHP.AX","CBA.AX","CSL.AX","WBC.AX", # Australia
    "AIA.NZ","SPK.NZ","FPH.NZ",          # New Zealand

    # 🌎 Americas - Currencies
    "USD=X","CAD=X","MXN=X","BRL=X","ARS=X","CLP=X","PEN=X","COP=X",

    # 🌍 Europe & Africa - Currencies
    "GBP=X","EUR=X","PLN=X","TRY=X","EGP=X","ZAR=X","KES=X","NGN=X","MAD=X",

    # 🌏 Middle East & Asia - Currencies
    "AED=X","ILS=X","JOD=X","PKR=X","INR=X","NPR=X","BDT=X","LKR=X","THB=X",
    "SGD=X","MYR=X","IDR=X","CNY=X","TWD=X","JPY=X","KRW=X","KZT=X","UZS=X",
    "MNT=X","MMK=X",

    # 🌊 Oceania - Currencies
    "AUD=X","NZD=X",

    # 🪙 Crypto
    "BTC-USD","ETH-USD"
]

controls = st.columns([2,2,2,2,1])
with controls[0]:
    ticker = st.selectbox(tr("ticker_label", st.session_state.user_lang), tickers_list, index=0)
with controls[1]:
    period = st.selectbox(tr("period_label", st.session_state.user_lang), ["1mo","3mo","6mo","1y","2y","5y","10y","max"], index=2)
with controls[2]:
    interval = st.selectbox(tr("interval_label", st.session_state.user_lang), ["1d","1wk","1mo"], index=0)
with controls[3]:
    show_indicators = st.checkbox(tr("indicators_label", st.session_state.user_lang), value=True)
with controls[4]:
    run = st.button(tr("run_button", st.session_state.user_lang), type="primary")

st.markdown("---")

if run:
    # Fetch and process stock data
    with st.spinner(tr("fetching_data", st.session_state.user_lang)):
        df = fetch_yahoo_data(ticker, period, interval)
    
    if df.empty:
        st.error(tr("no_data", st.session_state.user_lang))
        st.stop()
    
    df = compute_indicators(df)
    
    # Get currency information
    currency_code, market = get_currency_info(ticker)

    # Display key metrics
    last = df.iloc[-1]
    metrics_cols = st.columns([1,1,1,1,1])
    with metrics_cols[0]: st.metric(tr("date", st.session_state.user_lang), str(pd.to_datetime(last['Date']).date()))
    with metrics_cols[1]: st.metric(tr("open", st.session_state.user_lang), format_currency(last['Open'], currency_code))
    with metrics_cols[2]: st.metric(tr("high", st.session_state.user_lang), format_currency(last['High'], currency_code))
    with metrics_cols[3]: st.metric(tr("low", st.session_state.user_lang), format_currency(last['Low'], currency_code))
    with metrics_cols[4]: st.metric(tr("close", st.session_state.user_lang), format_currency(last['Close'], currency_code))

    # Plot price chart with indicators
    st.subheader(tr("price_chart", st.session_state.user_lang))
    plot_advanced(df, f"{ticker} — {tr('price_chart', st.session_state.user_lang)}", show_indicators)

    # Create two columns for forecasts and news
    forecast_col, news_col = st.columns([1, 1])
    
    with forecast_col:
        st.subheader(tr("ai_forecasts", st.session_state.user_lang))
        with st.spinner(tr("running_models", st.session_state.user_lang)):
            forecasts = forecast_all(df, periods=30)
        
        if forecasts:
            for model_name, fc in forecasts.items():
                if fc is not None:
                    with st.expander(f" {tr(model_name.lower(), st.session_state.user_lang)} {tr('model', st.session_state.user_lang)}", expanded=False):
                        # Format forecast values with appropriate currency
                        fc_display = fc.copy()
                        if 'yhat' in fc_display.columns:
                            fc_display['yhat'] = fc_display['yhat'].apply(lambda x: format_currency(x, currency_code))
                        if 'yhat_lower' in fc_display.columns:
                            fc_display['yhat_lower'] = fc_display['yhat_lower'].apply(lambda x: format_currency(x, currency_code))
                        if 'yhat_upper' in fc_display.columns:
                            fc_display['yhat_upper'] = fc_display['yhat_upper'].apply(lambda x: format_currency(x, currency_code))
                            
                        st.dataframe(fc_display.head(10), use_container_width=True)
                        
                        # Plot forecast
                        fig = go.Figure()
                        fig.add_trace(go.Scatter(x=df['Date'].tail(50), y=df['Close'].tail(50), 
                                               name=tr('historical', st.session_state.user_lang), line=dict(color='#E6E6E6')))
                        fig.add_trace(go.Scatter(x=fc['Date'], y=fc['yhat'], 
                                               name=f'{tr(model_name.lower(), st.session_state.user_lang)} {tr("forecast", st.session_state.user_lang)}', line=dict(color='#4DA6FF')))
                        
                        if model_name == "Prophet" and 'yhat_lower' in fc.columns and 'yhat_upper' in fc.columns:
                            fig.add_trace(go.Scatter(x=fc['Date'], y=fc['yhat_lower'], 
                                                   name=tr('lower_bound', st.session_state.user_lang), line=dict(dash='dot', color='#666')))
                            fig.add_trace(go.Scatter(x=fc['Date'], y=fc['yhat_upper'], 
                                                   name=tr('upper_bound', st.session_state.user_lang), line=dict(dash='dot', color='#666')))
                        
                        fig.update_layout(template='plotly_dark', height=300,
                                        paper_bgcolor='#000000', plot_bgcolor='#000000')
                        st.plotly_chart(fig, use_container_width=True, theme=None)
                        
                        st.download_button(f"📥 {tr('download', st.session_state.user_lang)} {tr(model_name.lower(), st.session_state.user_lang)} CSV", 
                                         fc.to_csv(index=False), 
                                         file_name=f"{ticker}_{model_name}.csv", 
                                         mime="text/csv",
                                         key=f"download_{model_name}")
        else:
            st.warning(tr("no_models", st.session_state.user_lang))

    with news_col:
        st.subheader(tr("news", st.session_state.user_lang))
        
        # Get company name for better news search
        company_name = get_company_name(ticker)
        
        # Build news query
        query = ticker or ""
        if company_name:
            query = f'{ticker} OR "{company_name}"'
        
        # Language mapping for news API
        lang_map = {
            "en": ("en-US", "US", "US:en"),
            "es": ("es-ES", "ES", "ES:es"),
            "fr": ("fr-FR", "FR", "FR:fr"),
            "pt": ("pt-BR", "BR", "BR:pt"),
            "ta": ("ta-IN", "IN", "IN:ta"),
        }
        
        hl, gl, ceid = lang_map.get(st.session_state.user_lang, ("en-US", "US", "US:en"))
        
        with st.spinner(tr("fetching_news", st.session_state.user_lang)):
            articles = fetch_google_news(query, max_items=8, hl=hl, gl=gl, ceid=ceid)

        if not articles:
            st.markdown(f'<div class="empty"> {tr("no_articles", st.session_state.user_lang)}</div>', unsafe_allow_html=True)
        else:
            html_out = ['<div class="news-list">']
            for a in articles:
                # make safe values
                link = a["link"]
                title = html.escape(a["title"])
                src = html.escape(a["source"])
                pub = html.escape(a["published"])
                img = a.get("image")
                img_tag = ""
                if img:
                    img_url = img
                    if img_url.startswith("//"):
                        img_url = "https:" + img_url
                    if img_url.startswith("http://") or img_url.startswith("https://"):
                        img_tag = f'<img class="news-img" src="{html.escape(img_url, quote=True)}" loading="lazy" alt="thumb"/>'
                
                if img_tag:
                    card = f'''
<a class="card-link" href="{html.escape(link, quote=True)}" target="_blank" rel="noopener noreferrer">
  <div class="news-card">
    {img_tag}
    <div class="news-content">
      <div class="news-title">{title}</div>
      <div class="news-meta">{src} • {pub}</div>
    </div>
  </div>
</a>
'''
                else:
                    card = f'''
<a class="card-link" href="{html.escape(link, quote=True)}" target="_blank" rel="noopener noreferrer">
  <div class="news-card" style="align-items:center;">
    <div style="flex:1;">
      <div class="news-title">{title}</div>
      <div class="news-meta">{src} • {pub}</div>
    </div>
  </div>
</a>
'''
                html_out.append(card)
            html_out.append('</div>')
            st.markdown("".join(html_out), unsafe_allow_html=True)

    # Download raw data
    st.markdown("---")
    st.subheader(tr("export_data", st.session_state.user_lang))
    export_cols = st.columns([1,1,1])
    with export_cols[0]:
        st.download_button(f"📥 {tr('download_csv', st.session_state.user_lang)}", 
                         df.to_csv(index=False), 
                         file_name=f"{ticker}_complete_data.csv", 
                         mime="text/csv")
    with export_cols[1]:
        st.download_button(f"📥 {tr('download_json', st.session_state.user_lang)}", 
                         df.to_json(orient='records', date_format='iso'), 
                         file_name=f"{ticker}_historical.json", 
                         mime="application/json")
    with export_cols[2]:
        if articles:
            news_df = pd.DataFrame(articles)
            st.download_button(f"📥 {tr('download_news', st.session_state.user_lang)}", 
                             news_df.to_csv(index=False), 
                             file_name=f"{ticker}_news.csv", 
                             mime="text/csv")

    # Recent data table
    st.markdown("---")
    st.subheader(tr("recent_data", st.session_state.user_lang))
    st.dataframe(df.tail(20), use_container_width=True)

else:
    st.info(tr("select_ticker", st.session_state.user_lang))
    
    # Show model availability status
    st.markdown(f"### {tr('model_status', st.session_state.user_lang)}")
    status_cols = st.columns(4)
    with status_cols[0]:
        status = f"✅ {tr('available', st.session_state.user_lang)}" if HAS_PROPHET else f"❌ {tr('missing', st.session_state.user_lang)}"
        st.markdown(f"**{tr('prophet', st.session_state.user_lang)}:** {status}")
    with status_cols[1]:
        status = f"✅ {tr('available', st.session_state.user_lang)}" if HAS_ARIMA else f"❌ {tr('missing', st.session_state.user_lang)}"
        st.markdown(f"**{tr('arima', st.session_state.user_lang)}:** {status}")
    with status_cols[2]:
        status = f"✅ {tr('available', st.session_state.user_lang)}" if HAS_SKLEARN else f"❌ {tr('missing', st.session_state.user_lang)}"
        st.markdown(f"**{tr('random_forest', st.session_state.user_lang)}:** {status}")
    with status_cols[3]:
        status = f"✅ {tr('available', st.session_state.user_lang)}" if HAS_TF else f"❌ {tr('missing', st.session_state.user_lang)}"
        st.markdown(f"**{tr('lstm', st.session_state.user_lang)}:** {status}")
