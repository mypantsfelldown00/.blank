import warnings
warnings.filterwarnings("ignore")

import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from streamlit_plotly_events import plotly_events
from datetime import datetime, timedelta
import pytz
import feedparser
import urllib.parse
import html
import re
import time

# --------------------------
# ML libraries
# --------------------------
HAS_PROPHET = False
HAS_ARIMA = False
HAS_SKLEARN = False
HAS_TF = False

try:
    from prophet import Prophet
    HAS_PROPHET = True
except:
    Prophet = None

try:
    from statsmodels.tsa.arima.model import ARIMA
    HAS_ARIMA = True
except:
    ARIMA = None

try:
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.preprocessing import MinMaxScaler
    HAS_SKLEARN = True
except:
    RandomForestRegressor = None
    MinMaxScaler = None

try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers
    HAS_TF = True
except:
    tf = None
    keras = None
    layers = None

# --------------------------
# Streamlit page config + CSS
# --------------------------
st.set_page_config(page_title="POINT.BLANK", layout="wide")

st.markdown("""
<style>
:root{--bg:#000;--card:#0F0F10;--muted:#9E9E9E;--accent:#4DA6FF;--border:#2C2C2E;}
body, .stApp {background-color: #000000; color: #E6E6E6; font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Display', Roboto, sans-serif;}
.block-container {padding-top: 1.5rem; max-width: 1150px; margin-left:auto; margin-right:auto;}
.stButton>button {background-color: #1C1C1E; color: #E6E6E6; border-radius: 12px; border: 1px solid #2C2C2E; padding: 0.55em 1em;}
.stTextInput>div>div>input, .stSelectbox>div>div, .stSlider>div>div {background-color: #0F0F10; color: #E6E6E6; border-radius: 10px; border: 1px solid #222224;}
.stCheckbox>div, .stRadio>div {color: #E6E6E6;}
h1, h2, h3, h4 {color: #E6E6E6; text-align: center;}
.model-availability {background-color:#0B0B0C; padding:8px; border-radius:8px; border:1px solid #202022;}
.news-list {margin-top:10px;}
a.card-link { text-decoration:none; color:inherit; display:block; }
.news-card { background:var(--card); border:1px solid var(--border); border-radius:14px; padding:12px; margin-bottom:12px; display:flex; gap:14px; align-items:flex-start; transition: transform .06s ease, box-shadow .06s ease; }
.news-card:hover { transform: translateY(-4px); box-shadow: 0 6px 20px rgba(0,0,0,0.5); }
.news-img { width:120px; height:80px; object-fit:cover; border-radius:10px; flex-shrink:0; background:#050505; }
.news-content { flex:1; min-width:0; }
.news-title { font-weight:600; color:#E6E6E6; font-size:15px; line-height:1.3; margin-bottom:6px; overflow-wrap: anywhere; }
.news-meta { font-size:12px; color:var(--muted); }
.empty { color:var(--muted); padding:12px; border-radius:10px; background:#070707; border:1px solid #202022; }
</style>
""", unsafe_allow_html=True)

# --------------------------
# Disclaimer Gate
# --------------------------
st.markdown("## ️ DISCLAIMER")
st.markdown("""
Point blank provides stock market data, analysis, and predictive tools for **educational and informational purposes only**.  

- Point blank does **not** provide financial, investment, trading, or legal advice.  
- All information, forecasts, and analytics generated by Point blank are **estimates only** and may be inaccurate, incomplete, or outdated.  
- Stock market investments are inherently **risky and volatile**. Past performance is not indicative of future results.  
- Users are solely responsible for any investment or trading decisions made based on Point blank's content.  
- The developers, owners, affiliates, and contributors of Point blank shall **not be held liable** for any financial losses, damages, or consequences arising directly or indirectly from its use.  

By using Point blank, you acknowledge that you understand these risks and agree to use the website at your own discretion and responsibility.  
For personalized financial guidance, please consult a licensed financial advisor.
""")

accept = st.checkbox(" I have read and accept the disclaimer")

if not accept:
    st.warning("⚠️ Please accept the disclaimer to use the app.")
    st.stop()
import streamlit as st
import plotly.graph_objects as go
from streamlit_plotly_events import plotly_events
from datetime import datetime
import pytz

st.set_page_config(page_title="POINTBLANK", layout="wide")
st.title("POINT.BLANK")

# ------------------------------
# Expanded City list with timezones (covering all major zones)
# ------------------------------
cities = [
    # Pacific & Americas
    {"city": "Honolulu", "lat": 21.3069, "lon": -157.8583, "timezone": "Pacific/Honolulu"},
    {"city": "Anchorage", "lat": 61.2181, "lon": -149.9003, "timezone": "America/Anchorage"},
    {"city": "Los Angeles", "lat": 34.0522, "lon": -118.2437, "timezone": "America/Los_Angeles"},
    {"city": "Denver", "lat": 39.7392, "lon": -104.9903, "timezone": "America/Denver"},
    {"city": "Chicago", "lat": 41.8781, "lon": -87.6298, "timezone": "America/Chicago"},
    {"city": "New York", "lat": 40.7128, "lon": -74.0060, "timezone": "America/New_York"},
    {"city": "Toronto", "lat": 43.6532, "lon": -79.3832, "timezone": "America/Toronto"},
    {"city": "Mexico City", "lat": 19.4326, "lon": -99.1332, "timezone": "America/Mexico_City"},
    {"city": "São Paulo", "lat": -23.5505, "lon": -46.6333, "timezone": "America/Sao_Paulo"},
    {"city": "Buenos Aires", "lat": -34.6037, "lon": -58.3816, "timezone": "America/Argentina/Buenos_Aires"},
    {"city": "Santiago", "lat": -33.4489, "lon": -70.6693, "timezone": "America/Santiago"},
    {"city": "Lima", "lat": -12.0464, "lon": -77.0428, "timezone": "America/Lima"},
    {"city": "Caracas", "lat": 10.4806, "lon": -66.9036, "timezone": "America/Caracas"},
    {"city": "Bogotá", "lat": 4.7110, "lon": -74.0721, "timezone": "America/Bogota"},
    {"city": "Phoenix", "lat": 33.4484, "lon": -112.0740, "timezone": "America/Phoenix"},
    {"city": "Adak", "lat": 51.8780, "lon": -176.6581, "timezone": "America/Adak"},

    # Europe & Africa
    {"city": "London", "lat": 51.5074, "lon": -0.1278, "timezone": "Europe/London"},
    {"city": "Lisbon", "lat": 38.7169, "lon": -9.1390, "timezone": "Europe/Lisbon"},
    {"city": "Paris", "lat": 48.8566, "lon": 2.3522, "timezone": "Europe/Paris"},
    {"city": "Berlin", "lat": 52.5200, "lon": 13.4050, "timezone": "Europe/Berlin"},
    {"city": "Rome", "lat": 41.9028, "lon": 12.4964, "timezone": "Europe/Rome"},
    {"city": "Madrid", "lat": 40.4168, "lon": -3.7038, "timezone": "Europe/Madrid"},
    {"city": "Dublin", "lat": 53.3331, "lon": -6.2489, "timezone": "Europe/Dublin"},
    {"city": "Athens", "lat": 37.9838, "lon": 23.7275, "timezone": "Europe/Athens"},
    {"city": "Helsinki", "lat": 60.1699, "lon": 24.9384, "timezone": "Europe/Helsinki"},
    {"city": "Warsaw", "lat": 52.2297, "lon": 21.0122, "timezone": "Europe/Warsaw"},
    {"city": "Moscow", "lat": 55.7558, "lon": 37.6173, "timezone": "Europe/Moscow"},
    {"city": "Istanbul", "lat": 41.0082, "lon": 28.9784, "timezone": "Europe/Istanbul"},
    {"city": "Cairo", "lat": 30.0444, "lon": 31.2357, "timezone": "Africa/Cairo"},
    {"city": "Johannesburg", "lat": -26.2041, "lon": 28.0473, "timezone": "Africa/Johannesburg"},
    {"city": "Nairobi", "lat": -1.2921, "lon": 36.8219, "timezone": "Africa/Nairobi"},
    {"city": "Lagos", "lat": 6.5244, "lon": 3.3792, "timezone": "Africa/Lagos"},
    {"city": "Casablanca", "lat": 33.5731, "lon": -7.5898, "timezone": "Africa/Casablanca"},

    # Middle East & Asia
    {"city": "Dubai", "lat": 25.276987, "lon": 55.296249, "timezone": "Asia/Dubai"},
    {"city": "Tehran", "lat": 35.6892, "lon": 51.3890, "timezone": "Asia/Tehran"},
    {"city": "Jerusalem", "lat": 31.7683, "lon": 35.2137, "timezone": "Asia/Jerusalem"},
    {"city": "Amman", "lat": 31.9497, "lon": 35.9323, "timezone": "Asia/Amman"},
    {"city": "Karachi", "lat": 24.8607, "lon": 67.0011, "timezone": "Asia/Karachi"},
    {"city": "Delhi", "lat": 28.6139, "lon": 77.2090, "timezone": "Asia/Kolkata"},
    {"city": "Kathmandu", "lat": 27.7172, "lon": 85.3240, "timezone": "Asia/Kathmandu"},
    {"city": "Dhaka", "lat": 23.8103, "lon": 90.4125, "timezone": "Asia/Dhaka"},
    {"city": "Colombo", "lat": 6.9271, "lon": 79.8612, "timezone": "Asia/Colombo"},
    {"city": "Bangkok", "lat": 13.7563, "lon": 100.5018, "timezone": "Asia/Bangkok"},
    {"city": "Singapore", "lat": 1.3521, "lon": 103.8198, "timezone": "Asia/Singapore"},
    {"city": "Kuala Lumpur", "lat": 3.1390, "lon": 101.6869, "timezone": "Asia/Kuala_Lumpur"},
    {"city": "Jakarta", "lat": -6.2088, "lon": 106.8456, "timezone": "Asia/Jakarta"},
    {"city": "Shanghai", "lat": 31.2304, "lon": 121.4737, "timezone": "Asia/Shanghai"},
    {"city": "Taipei", "lat": 25.0330, "lon": 121.5654, "timezone": "Asia/Taipei"},
    {"city": "Tokyo", "lat": 35.6762, "lon": 139.6503, "timezone": "Asia/Tokyo"},
    {"city": "Seoul", "lat": 37.5665, "lon": 126.9780, "timezone": "Asia/Seoul"},
    {"city": "Almaty", "lat": 43.2220, "lon": 76.8512, "timezone": "Asia/Almaty"},
    {"city": "Tashkent", "lat": 41.2995, "lon": 69.2401, "timezone": "Asia/Tashkent"},
    {"city": "Ulaanbaatar", "lat": 47.8864, "lon": 106.9057, "timezone": "Asia/Ulaanbaatar"},
    {"city": "Yangon", "lat": 16.8409, "lon": 96.1735, "timezone": "Asia/Yangon"},

    # Oceania
    {"city": "Sydney", "lat": -33.8688, "lon": 151.2093, "timezone": "Australia/Sydney"},
    {"city": "Melbourne", "lat": -37.8136, "lon": 144.9631, "timezone": "Australia/Melbourne"},
    {"city": "Brisbane", "lat": -27.4698, "lon": 153.0251, "timezone": "Australia/Brisbane"},
    {"city": "Adelaide", "lat": -34.9285, "lon": 138.6007, "timezone": "Australia/Adelaide"},
    {"city": "Perth", "lat": -31.9505, "lon": 115.8605, "timezone": "Australia/Perth"},
    {"city": "Auckland", "lat": -36.8485, "lon": 174.7633, "timezone": "Pacific/Auckland"},
    {"city": "Fiji", "lat": -18.1416, "lon": 178.4419, "timezone": "Pacific/Fiji"},
    {"city": "Noumea", "lat": -22.2763, "lon": 166.4572, "timezone": "Pacific/Noumea"},
    {"city": "Guadalcanal", "lat": -9.4456, "lon": 160.1960, "timezone": "Pacific/Guadalcanal"},
]


# ------------------------------
# Session state for selected city
# ------------------------------
if "selected_city_index" not in st.session_state:
    st.session_state.selected_city_index = 0

# ------------------------------
# Prepare ScatterGeo figure
# ------------------------------
lons = [c["lon"] for c in cities]
lats = [c["lat"] for c in cities]
texts = [c["city"] for c in cities]

fig = go.Figure(go.Scattergeo(
    lon=lons,
    lat=lats,
    mode="markers+text",
    text=texts,
    textposition="top center",
    marker=dict(size=7, color="red", symbol="circle")
))

fig.update_geos(
    projection_type="orthographic",
    showland=True,
    landcolor="rgb(255, 255, 255)",
    showcountries=True,
    countrycolor="black",
    showocean=True,
    oceancolor="rgb(255, 255, 255)",
    showcoastlines=True,
    coastlinecolor="black",
    showframe=False,
    showlakes=False,
    showrivers=False,
    lonaxis=dict(showgrid=True, gridcolor="lightgray", dtick=30),
    lataxis=dict(showgrid=True, gridcolor="lightgray", dtick=15),
)

fig.update_layout(
    geo=dict(projection_scale=0.6, center=dict(lat=0, lon=0)),
    margin={"r":0,"t":0,"l":0,"b":0},
    paper_bgcolor="white",
    font_color="black"
)

# ------------------------------
# Show the globe (only click selection)
# ------------------------------
clicked_points = plotly_events(fig, click_event=True, hover_event=False)

if clicked_points:
    st.session_state.selected_city_index = clicked_points[0]["pointNumber"]

selected_city = cities[st.session_state.selected_city_index]

# ------------------------------
# Digital live clock (no infinite loop)
# ------------------------------
tz = pytz.timezone(selected_city["timezone"])
current_time = datetime.now(tz).strftime("%I:%M:%S %p")

st.markdown(
    f"""
    <div style="font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Display', 'Helvetica Neue', Arial, sans-serif;
                font-size: 36px; font-weight: 600; color: white;">
        Current Time in {selected_city['city']}: {current_time}
    </div>
    """,
    unsafe_allow_html=True
)


@st.cache_data(ttl=300)
def fetch_yahoo_data(ticker: str, period="6mo", interval="1d") -> pd.DataFrame:
    try:
        t = yf.Ticker(ticker)
        df = t.history(period=period, interval=interval)
        if df is None or df.empty:
            return pd.DataFrame()
        df = df.reset_index()
        df['Date'] = pd.to_datetime(df['Date'])
        try:
            df['Date'] = df['Date'].dt.tz_localize(None)
        except Exception:
            df['Date'] = pd.to_datetime(df['Date']).dt.tz_localize(None)
        for col in ['Open','High','Low','Close','Volume']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        df = df.dropna(subset=['Date','Close']).reset_index(drop=True)
        return df
    except Exception:
        return pd.DataFrame()

def compute_indicators(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy().reset_index(drop=True)
    df['MA20'] = df['Close'].rolling(20).mean()
    df['MA50'] = df['Close'].rolling(50).mean()
    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = df['EMA12'] - df['EMA26']
    df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
    df['BB_MID'] = df['Close'].rolling(20).mean()
    df['BB_STD'] = df['Close'].rolling(20).std(ddof=0).fillna(0)
    df['BB_UP'] = df['BB_MID'] + 2*df['BB_STD']
    df['BB_LOW'] = df['BB_MID'] - 2*df['BB_STD']
    delta = df['Close'].diff()
    up = delta.clip(lower=0)
    down = -delta.clip(upper=0)
    roll_up = up.rolling(14).mean()
    roll_down = down.rolling(14).mean()
    rs = roll_up / (roll_down + 1e-8)
    df['RSI'] = 100 - (100 / (1 + rs))
    df['RSI'] = df['RSI'].clip(0,100).fillna(50)
    return df

def plot_advanced(df: pd.DataFrame, title: str, show_indicators: bool = True):
    fig = make_subplots(rows=3, cols=1, shared_xaxes=True,
                        row_heights=[0.6,0.18,0.22],
                        vertical_spacing=0.03)
    fig.add_trace(go.Candlestick(x=df['Date'], open=df['Open'], high=df['High'],
                                 low=df['Low'], close=df['Close'], name='Price'), row=1, col=1)
    if show_indicators:
        fig.add_trace(go.Scatter(x=df['Date'], y=df['MA20'], name='MA20', line=dict(width=1.4)), row=1, col=1)
        fig.add_trace(go.Scatter(x=df['Date'], y=df['MA50'], name='MA50', line=dict(width=1.4, dash='dash')), row=1, col=1)
        fig.add_trace(go.Scatter(x=df['Date'], y=df['BB_UP'], name='BB_UP', line=dict(width=1, dash='dot')), row=1, col=1)
        fig.add_trace(go.Scatter(x=df['Date'], y=df['BB_LOW'], name='BB_LOW', line=dict(width=1, dash='dot')), row=1, col=1)
    fig.add_trace(go.Bar(x=df['Date'], y=df['Volume'], name='Volume', marker_color='gray', opacity=0.3), row=2, col=1)
    fig.add_trace(go.Scatter(x=df['Date'], y=df['RSI'], name='RSI', line=dict(width=1.2)), row=3, col=1)
    fig.add_hline(y=70, line_dash='dot', row=3, col=1)
    fig.add_hline(y=30, line_dash='dot', row=3, col=1)
    fig.update_layout(template='plotly_dark', title=title,
                      margin=dict(l=20,r=20,t=40,b=10),
                      paper_bgcolor='#000000', plot_bgcolor='#000000',
                      legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1))
    st.plotly_chart(fig, use_container_width=True, theme=None)

# --------------------------
# Forecasting Models
# --------------------------
def forecast_all(df: pd.DataFrame, periods: int = 30):
    forecasts = {}
    if HAS_PROPHET:
        try:
            prophet_df = df[['Date','Close']].rename(columns={'Date':'ds','Close':'y'}).copy()
            prophet_df['ds'] = pd.to_datetime(prophet_df['ds']).dt.tz_localize(None)
            m = Prophet(daily_seasonality=True, yearly_seasonality=True, weekly_seasonality=True)
            m.fit(prophet_df)
            future = m.make_future_dataframe(periods=periods, freq='D')
            future['ds'] = pd.to_datetime(future['ds']).dt.tz_localize(None)
            fc = m.predict(future)[['ds','yhat','yhat_lower','yhat_upper']].rename(columns={'ds':'Date'})
            forecasts['Prophet'] = fc
        except Exception as e:
            st.error(f"Prophet error: {e}")

    if HAS_ARIMA:
        try:
            series = df.set_index('Date')['Close'].sort_index()
            series.index = pd.to_datetime(series.index).tz_localize(None)
            daily_idx = pd.date_range(series.index.min(), series.index.max(), freq='D')
            series = series.reindex(daily_idx).ffill()
            model = ARIMA(series, order=(5,1,0)).fit()
            fc = model.forecast(steps=periods)
            dates = pd.date_range(start=series.index[-1]+timedelta(days=1), periods=periods)
            forecasts['ARIMA'] = pd.DataFrame({'Date': dates, 'yhat': fc.values})
        except Exception as e:
            st.error(f"ARIMA error: {e}")

    if HAS_SKLEARN:
        try:
            data = df[['Close']].copy()
            n_lags = 5
            for lag in range(1,n_lags+1):
                data[f'lag_{lag}'] = data['Close'].shift(lag)
            data = data.dropna()
            X = data[[f'lag_{i}' for i in range(1,n_lags+1)]].values
            y = data['Close'].values
            model = RandomForestRegressor(n_estimators=200, random_state=42)
            model.fit(X, y)
            last_window = X[-1].tolist()
            preds = []
            for _ in range(periods):
                p = float(model.predict([last_window]))
                preds.append(p)
                last_window = [p]+last_window[:-1]
            dates = pd.date_range(start=df['Date'].iloc[-1]+timedelta(days=1), periods=periods)
            forecasts['RandomForest'] = pd.DataFrame({'Date': dates, 'yhat': preds})
        except Exception as e:
            st.error(f"RandomForest error: {e}")

    if HAS_TF and HAS_SKLEARN:
        try:
            values = df['Close'].values.astype('float32')
            n_lags = 20
            scaler = MinMaxScaler()
            scaled = scaler.fit_transform(values.reshape(-1,1)).flatten()
            X, y = [], []
            for i in range(n_lags, len(scaled)):
                X.append(scaled[i-n_lags:i])
                y.append(scaled[i])
            X = np.array(X).reshape(-1, n_lags, 1)
            y = np.array(y)
            tf.keras.backend.clear_session()
            model = keras.Sequential([
                layers.Input(shape=(n_lags,1)),
                layers.LSTM(64, return_sequences=False),
                layers.Dense(32, activation='relu'),
                layers.Dense(1)
            ])
            model.compile(optimizer='adam', loss='mse')
            model.fit(X, y, epochs=10, batch_size=16, verbose=0)
            last_window = list(scaled[-n_lags:])
            preds_scaled = []
            for _ in range(periods):
                x = np.array(last_window).reshape(1, n_lags, 1)
                p = float(model.predict(x, verbose=0)[0,0])
                preds_scaled.append(p)
                last_window = last_window[1:]+[p]
            preds = scaler.inverse_transform(np.array(preds_scaled).reshape(-1,1)).flatten().tolist()
            dates = pd.date_range(start=df['Date'].iloc[-1]+timedelta(days=1), periods=periods)
            forecasts['LSTM'] = pd.DataFrame({'Date': dates, 'yhat': preds})
        except Exception as e:
            st.error(f"LSTM error: {e}")

    return forecasts

# --------------------------
# News Utilities
# --------------------------
@st.cache_data(ttl=360)
def get_company_name(ticker: str) -> str:
    if not ticker:
        return ""
    try:
        info = yf.Ticker(ticker).info
        return info.get("shortName") or info.get("longName") or ""
    except Exception:
        return ""

def _format_time(entry) -> str:
    try:
        if entry.get("published_parsed"):
            ts = time.mktime(entry.published_parsed)
            return datetime.fromtimestamp(ts).strftime("%a, %d %b %Y %H:%M:%S")
        if entry.get("published"):
            return str(entry.get("published"))
    except Exception:
        pass
    return "Unknown time"

def _extract_image(entry) -> str | None:
    # try common RSS fields
    mc = entry.get("media_content") or entry.get("mediaContents")
    if mc and isinstance(mc, (list, tuple)) and mc:
        first = mc[0]
        if isinstance(first, dict):
            url = first.get("url") or first.get("value")
            if url:
                return url
    mt = entry.get("media_thumbnail")
    if mt and isinstance(mt, (list, tuple)) and mt:
        try:
            return mt[0].get("url")
        except Exception:
            pass
    for l in entry.get("links", []):
        t = l.get("type", "")
        if t and t.startswith("image"):
            return l.get("href")
        if l.get("rel") == "enclosure" and l.get("href"):
            return l.get("href")
    # fallback: parse summary/description <img>
    summary = entry.get("summary", "") or entry.get("description", "")
    m = re.search(r'<img[^>]+src=["\']([^"\']+)["\']', summary or "", re.IGNORECASE)
    if m:
        return m.group(1)
    return None

def _resolve_link(entry, feed) -> str:
    # 1) prefer a non-news.google.com alternate link (links array)
    for l in entry.get("links", []):
        href = l.get("href") or ""
        rel = l.get("rel", "")
        typ = l.get("type", "")
        if href and "news.google.com" not in href and (rel == "alternate" or typ.startswith("text/html") or typ == ""):
            return href
    # 2) look in summary/description for first external href
    summary = entry.get("summary", "") or entry.get("description", "")
    m = re.search(r'href=["\'](https?://[^"\']+)["\']', summary or "", re.IGNORECASE)
    if m:
        href = m.group(1)
        if "news.google.com" not in href:
            return href
    # 3) try extracting 'url=' query param from entry.link (google redirect)
    link = entry.get("link", "") or ""
    if "url=" in link:
        qs = urllib.parse.parse_qs(urllib.parse.urlparse(link).query).get("url")
        if qs:
            candidate = qs[0]
            if candidate and "news.google.com" not in candidate:
                return candidate
    # 4) fallback: entry.link (may be Google News article)
    if link:
        return link
    # 5) feed-level link fallback
    return feed.feed.get("link") or ""

@st.cache_data(ttl=300)
def fetch_google_news(query: str, max_items: int = 8, hl: str = "en-US", gl: str = "US", ceid: str = "US:en"):
    if not query:
        return []
    encoded = urllib.parse.quote_plus(query)
    rss_url = f"https://news.google.com/rss/search?q={encoded}&hl={hl}&gl={gl}&ceid={ceid}"
    feed = feedparser.parse(rss_url)
    entries = feed.entries or []
    items = []
    seen = set()
    for entry in entries:
        try:
            title = html.unescape(entry.get("title", "")).strip() or "(no title)"
            published = _format_time(entry)
            # source
            src = ""
            s = entry.get("source")
            if isinstance(s, dict):
                src = s.get("title", "") or ""
            if not src:
                src = feed.feed.get("title", "") or entry.get("publisher", "") or "Unknown source"
            image = _extract_image(entry)
            link = _resolve_link(entry, feed)
            if not link:
                continue
            # dedupe by resolved link
            if link in seen:
                continue
            seen.add(link)
            items.append({
                "title": title,
                "link": link,
                "published": published,
                "source": src,
                "image": image
            })
            if len(items) >= max_items:
                break
        except Exception:
            continue
    return items

# --------------------------
# Main UI
# --------------------------
st.title("")
st.markdown("")

tickers_list = [
    # 🌎 Americas
    "AAPL","MSFT","AMZN","TSLA","JPM",   # New York
    "RY.TO","SHOP.TO","ENB.TO","ABX.TO", # Toronto
    "AMXL.MX","BIMBOA.MX","CEMEXCPO.MX", # Mexico City
    "PETR4.SA","VALE3.SA","ITUB4.SA",    # São Paulo
    "YPFD.BA","GGAL.BA","TEO.BA",        # Buenos Aires
    "CHILE.SN","ENELAM.SN","SQM.SN",     # Santiago
    "BAP.LM","BVN.LM","SCCO.LM",         # Lima
    "CIB","AVAL",                        # Bogotá (Ecopetrol trades as EC in US ADRs)
    
    # 🌍 Europe & Africa
    "HSBA.L","BP.L","ULVR.L","BARC.L",   # London
    "MC.PA","TTE.PA","AIR.PA","SAN.PA",  # Paris
    "SIE.DE","VOW3.DE","SAP.DE","ALV.DE",# Frankfurt
    "ENI.MI","ISP.MI","RACE.MI",         # Milan/Rome
    "SAN.MC","TEF.MC","IBE.MC",          # Madrid
    "RYA.IR","CRH.IR","KYGA.IR",         # Dublin
    "ETE.AT","HTO.AT",                   # Athens
    "NOKIA.HE","KNEBV.HE","NESTE.HE",    # Helsinki
    "PKO.WA","PKN.WA","KGH.WA",          # Warsaw
    "TCELL.IS","GARAN.IS","AEFES.IS",    # Istanbul
    "COMI.CA","ETEL.CA",                 # Cairo
    "SOLJ.J","NPN.J","AGLJ.J",           # Johannesburg
    "SCOM.NR","EQTY.NR","KCB.NR",        # Nairobi
    "DANGCEM.LG","MTNN.LG","ZENITH.LG",  # Lagos
    "ATW.CS","IAM.CS",                   # Casablanca
    
    # 🌏 Middle East & Asia
    "EMAAR.DU","DIB.DU",                 # Dubai
    "TEVA.TA","LUMI.TA",                 # Tel Aviv
    "ARBK.AM","THBK.AM",                 # Amman
    "OGDC.KA","HBL.KA",                  # Karachi
    "RELIANCE.NS","TCS.NS","INFY.NS","HDFCBANK.NS", # Delhi (India)
    "NTC.NP","NABIL.NP",                 # Kathmandu
    "GP.DH","SQURPHARMA.DH",             # Dhaka
    "JKH.CM","COMB.CM",                  # Colombo
    "PTT.BK","SCC.BK","BBL.BK",          # Bangkok
    "D05.SI","Z74.SI","BN4.SI",          # Singapore
    "MAYBANK.KL","PCHEM.KL","TENAGA.KL", # Kuala Lumpur
    "BBCA.JK","TLKM.JK",                 # Jakarta
    "601398.SS","601857.SS","600104.SS", # Shanghai
    "2330.TW","2317.TW","2454.TW",       # Taipei
    "7203.T","6758.T","9984.T","7974.T", # Tokyo
    "005930.KQ","005380.KQ","000660.KQ", # Seoul
    "KMGZ.KZ","HSBK.KZ",                 # Almaty
    "UZAUTO.UZ",                         # Tashkent
    "APU.MN","TTL.MN",                   # Ulaanbaatar
    "FMI.MM","MTSH.MM",                  # Yangon
    
    # 🌊 Oceania
    "BHP.AX","CBA.AX","CSL.AX","WBC.AX", # Sydney/Melbourne/Brisbane/Perth/Adelaide
    "AIA.NZ","SPK.NZ","FPH.NZ",          # Auckland
    
    # Crypto
    "BTC-USD","ETH-USD"
]


controls = st.columns([2,2,2,2,1])
with controls[0]:
    ticker = st.selectbox("Ticker", tickers_list, index=0)
with controls[1]:
    period = st.selectbox("History period", ["1mo","3mo","6mo","1y","2y","5y","10y","max"], index=2)
with controls[2]:
    interval = st.selectbox("Interval", ["1d","1wk","1mo"], index=0)
with controls[3]:
    show_indicators = st.checkbox("Show Indicators", value=True)
with controls[4]:
    run = st.button(" Run All", type="primary")

st.markdown("---")

if run:
    # Fetch and process stock data
    with st.spinner("Fetching stock data and computing indicators..."):
        df = fetch_yahoo_data(ticker, period, interval)
    
    if df.empty:
        st.error("❌ No data retrieved. Check ticker or network connection.")
        st.stop()
    
    df = compute_indicators(df)

    # Display key metrics
    last = df.iloc[-1]
    metrics_cols = st.columns([1,1,1,1,1])
    with metrics_cols[0]: st.metric("Date", str(pd.to_datetime(last['Date']).date()))
    with metrics_cols[1]: st.metric("Open", f"${last['Open']:.2f}")
    with metrics_cols[2]: st.metric("High", f"${last['High']:.2f}")
    with metrics_cols[3]: st.metric("Low", f"${last['Low']:.2f}")
    with metrics_cols[4]: st.metric("Close", f"${last['Close']:.2f}")

    # Plot price chart with indicators
    st.subheader(" Price Chart & Technical Indicators")
    plot_advanced(df, f"{ticker} — Price & Indicators", show_indicators)

    # Create two columns for forecasts and news
    forecast_col, news_col = st.columns([1, 1])
    
    with forecast_col:
        st.subheader(" AI Forecasts")
        with st.spinner("Running forecasting models..."):
            forecasts = forecast_all(df, periods=30)
        
        if forecasts:
            for model_name, fc in forecasts.items():
                with st.expander(f" {model_name} Model", expanded=False):
                    st.dataframe(fc.head(10), use_container_width=True)
                    
                    # Plot forecast
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(x=df['Date'].tail(50), y=df['Close'].tail(50), 
                                           name='Historical', line=dict(color='#E6E6E6')))
                    fig.add_trace(go.Scatter(x=fc['Date'], y=fc['yhat'], 
                                           name=f'{model_name} Forecast', line=dict(color='#4DA6FF')))
                    
                    if model_name == "Prophet" and 'yhat_lower' in fc.columns and 'yhat_upper' in fc.columns:
                        fig.add_trace(go.Scatter(x=fc['Date'], y=fc['yhat_lower'], 
                                               name='Lower Bound', line=dict(dash='dot', color='#666')))
                        fig.add_trace(go.Scatter(x=fc['Date'], y=fc['yhat_upper'], 
                                               name='Upper Bound', line=dict(dash='dot', color='#666')))
                    
                    fig.update_layout(template='plotly_dark', height=300,
                                    paper_bgcolor='#000000', plot_bgcolor='#000000')
                    st.plotly_chart(fig, use_container_width=True, theme=None)
                    
                    st.download_button(f"📥 Download {model_name} CSV", 
                                     fc.to_csv(index=False), 
                                     file_name=f"{ticker}_{model_name}.csv", 
                                     mime="text/csv",
                                     key=f"download_{model_name}")
        else:
            st.warning("⚠️ No forecasting models available. Install required libraries (prophet, statsmodels, sklearn, tensorflow).")

    with news_col:
        st.subheader(" NEWS")
        
        # Get company name for better news search
        company_name = get_company_name(ticker)
        
        # Build news query
        query = ticker or ""
        if company_name:
            query = f'{ticker} OR "{company_name}"'
        
        with st.spinner("Fetching latest news..."):
            articles = fetch_google_news(query, max_items=8, hl="en-US", gl="US", ceid="US:en")

        if not articles:
            st.markdown('<div class="empty"> No recent articles found.</div>', unsafe_allow_html=True)
        else:
            html_out = ['<div class="news-list">']
            for a in articles:
                # make safe values
                link = a["link"]
                title = html.escape(a["title"])
                src = html.escape(a["source"])
                pub = html.escape(a["published"])
                img = a.get("image")
                img_tag = ""
                if img:
                    img_url = img
                    if img_url.startswith("//"):
                        img_url = "https:" + img_url
                    if img_url.startswith("http://") or img_url.startswith("https://"):
                        img_tag = f'<img class="news-img" src="{html.escape(img_url, quote=True)}" loading="lazy" alt="thumb"/>'
                
                if img_tag:
                    card = f'''
<a class="card-link" href="{html.escape(link, quote=True)}" target="_blank" rel="noopener noreferrer">
  <div class="news-card">
    {img_tag}
    <div class="news-content">
      <div class="news-title">{title}</div>
      <div class="news-meta">{src} • {pub}</div>
    </div>
  </div>
</a>
'''
                else:
                    card = f'''
<a class="card-link" href="{html.escape(link, quote=True)}" target="_blank" rel="noopener noreferrer">
  <div class="news-card" style="align-items:center;">
    <div style="flex:1;">
      <div class="news-title">{title}</div>
      <div class="news-meta">{src} • {pub}</div>
    </div>
  </div>
</a>
'''
                html_out.append(card)
            html_out.append('</div>')
            st.markdown("".join(html_out), unsafe_allow_html=True)

    # Download raw data
    st.markdown("---")
    st.subheader(" Export Data")
    export_cols = st.columns([1,1,1])
    with export_cols[0]:
        st.download_button(" Download Raw Data (CSV)", 
                         df.to_csv(index=False), 
                         file_name=f"{ticker}_complete_data.csv", 
                         mime="text/csv")
    with export_cols[1]:
        st.download_button(" Download Historical Data (JSON)", 
                         df.to_json(orient='records', date_format='iso'), 
                         file_name=f"{ticker}_historical.json", 
                         mime="application/json")
    with export_cols[2]:
        if articles:
            news_df = pd.DataFrame(articles)
            st.download_button(" Download News Data (CSV)", 
                             news_df.to_csv(index=False), 
                             file_name=f"{ticker}_news.csv", 
                             mime="text/csv")

    # Recent data table
    st.markdown("---")
    st.subheader(" Recent Historical Data")
    st.dataframe(df.tail(20), use_container_width=True)

else:
    st.info(" Select a ticker and press **' Run'** to fetch comprehensive stock analysis with forecasts and news!")
    
    # Show model availability status
    st.markdown("###  Model Availability Status")
    status_cols = st.columns(4)
    with status_cols[0]:
        status = "✅ Available" if HAS_PROPHET else "❌ Missing"
        st.markdown(f"**Prophet:** {status}")
    with status_cols[1]:
        status = "✅ Available" if HAS_ARIMA else "❌ Missing"
        st.markdown(f"**ARIMA:** {status}")
    with status_cols[2]:
        status = "✅ Available" if HAS_SKLEARN else "❌ Missing"
        st.markdown(f"**Random Forest:** {status}")
    with status_cols[3]:
        status = "✅ Available" if HAS_TF else "❌ Missing"
        st.markdown(f"**LSTM:** {status}")
